\mychapter{Revisão Bibliográfica}{chp:Revisão Bibliográfica} %O que estão fazendo hoje??
\lhead{Revisão Bibliográfica}

% Breve resumo do capítulo.
  \lettrine{E}{ste} capítulo tem como objetivo apresentar a revisão bibliográfica necessária para a realização deste trabalho.

  
  
  
\iffalse

\section{Quão bons são os geradores de Números Pseudoaleatórios Disponíveis no R ?}
  No R há alguns geradores de números pseudoaleatórios bem como um pacote de testes, conhecido como Dieharder, para aferir a sua qualidade.
  Há por outro lado, uma metodologia para análise de séries temporais baseada em ferramentas da teoria da informação que se mostrou útil para avaliar geradores de números pseudoaleatórios.
  A proposta é avaliar os geradores disponíveis no R comparando os testes disponíveis no Dieharder com o teste baseado em ferramentas da teoria da informação.

\section{O que são PRNGs}
  \subsection{Geradores de Números Aleatórios?}
    A necessidade de números aleatórios e pseudoaleatórios surge em inúmeras aplicações, como aborda \citet{Knuth:98} :
    \begin{itemize}
     \item \textit{Simulação} - Quando um computador é usado para simular fenômenos naturais, números aleatórios são necessários para fazer as coisas de forma realística. Simulação abrange diversas áreas, desde o estudo de física nuclear (onde particulas são submetidas a colisões aleatórias) até pesquisa operacional (como, por exemplo, a taxa de pessoas que entram num aeroporto em intervalos aleatórios).
     \item \textit{Amostragem} - É praticamente impossível examinar todos os possíveis casos, porém uma amostra aleatória provê um palpite sobre como é o comportamento típico do fenômeno em questão.
     \item \textit{Análise Numérica} - Técnicas elaboradas para a solução de complexos problemas numéricos foram desenvolvidas utilizando-se números aleatórios.
     \item \textit{Programação de Computadores} - Valores aleatórios são uma ótima fonte de dados para testar a eficácia de algoritimos computacionais.
     \item \textit{Tomada de Decisão} - Existem relatos de que diversos executivos tomam suas decisões lançando moedas ou atirando dardos. Também há rumores de que professores universitários lançam suas notas de forma similar. Em alguns momentos é importante tomar decisões de forma não influenciada por qualquer agente externo.
     \item \textit{Criptografia} - Uma fonte de bits não viesada é essencial para diversos tipos de comunicações seguras, quando os dados precisam ser mantidos em sigilo.
     \item \textit{Estética} - Um pouco de aleatoriedade faz com que gráficos e músicas geradas por computador aparentem ser menos artificiais.
     \item \textit{Diversão} - Rolar dados, embaralhar cartas, girar rodas de roletas, etc., são passatempos facinantes para muitos. Estes usos tradicionais de números aleatórios sugeriram o nome ``Método de Monte Carlo''.
    \end{itemize}
    
 Existem dois tipos básicos de geradores utilizados para produzir sequências aleatórias: geradores de números aleatórios (RNGs) e geradores de números pseudoaleatórios (PRNGs). Ambos podem produzir um fluxo de zeros e uns, que podem ser divididos em blocos ou subcorrentes de números aleatórios. Uma seqüência de bits aleatórios poderia ser interpretada como o resultado dos lançamentos de uma moeda justa, imparcial com os lados que são identificados como ``0'' e ``1'', onde cada caso tem uma probabilidade de exatamente ½. Além disso, o resultado de qualquer lançamento anterior não influencia futuros lançamentos. A moeda imparcial justa é, portanto, o gerador de fluxo de bits aleatórios perfeito. Todos os elementos da sequência são gerados independentemente uns dos outros, e o valor do elemento seguinte na sequência não pode ser previsto, independentemente do número de elementos que já foram produzidos. Obviamente, a utilização de moedas imparciais para fins de criptografia, modelagem computacional ou simulação é impraticável. No entanto, a saída hipotética de um gerador de uma seqüência realmente aleatória serve como um ponto de referência para a avaliação dos geradores de números aleatórios e pseudoaleatórios.
    
    Números aleatórios e pseudoaleatórios gerados para quaisquer aplicações devem ser imprevisíveis. No caso de PRNG, se a semente é desconhecida, o próximo número na sequência de saída deve ser imprevisível, apesar de qualquer conhecimento de números aleatórios anteriores na sequência. Esta propriedade é conhecida como imprevisibilidade para a frente. Também não deve ser viável para determinar a semente conhecendo os valores gerados (ou seja, a imprevisibilidade para trás também é obrigatória). Nenhuma correlação entre uma semente e qualquer valor gerado a partir da mesma devem ser evidentes; cada elemento da sequência deve parecer ser o resultado de um evento aleatório independente, cuja probabilidade é de 1/2. Para garantir a imprevisibilidade para a frente, o cuidado deve ser exercido na obtenção de sementes. Os valores produzidos por um PRNG são completamente previsíveis se a semente e algoritmo de geração são conhecidos. Uma vez que em muitos casos
  \subsection{Propriedades desejadas de um gerador ideal}
    Um gerador de números pseudoaleatórios deve possuir algumas propriedades que garantam sua qualidade para um leigo a construção de um gerador de números aleatórios pode parecer uma tarefa simples e alguns programadores tem demonstrado ser relativamente fácil escrever programas que gerem sequências de números aparentemente imprevisíveis. Entretanto, é bastante complexo escrever um bom programa que gere sequências satisfatórias, ou seja, uma sequência virtualmete infinita de números aleatórios estatisticamente independentes entre 0 e 1. Pois sequências aparentemente imprevisíveis não são necessariamente aleatórios %\ref{Sibley:88}.
    %Vamos parafrasear algumas afirmações feitas por dois dos diversos autores que trataram o tema.
      \begin{itemize}
	\item\textit{D. H. Lehmer (1951)}: "Uma sequência aleatória é uma vaga noção baseada na ideia de uma sequência onde cada termo é imprevisível e cujos dígitos passam em um certo número de testes, tradicionais com estatísticas ou dependendo do uso no qual a sequência será utilizada."
	\item\textit{J. N. Franklin (1962)}: "A sequência é aleatória se possuir todas as propriedades compartilhadas por todas as infinitas sequências de amostras independentes de variáveis aleatórias sobre a distribuição uniforme.
      \end{itemize}
    A afirmação de Franklin essencialmente generaliza a de Lehmer ao dizer que a sequência precisa satisfazer \textit{todos} os testes estatísticos. Esta definição não é precisa e uma interpretação sensata leva-nos a concluir que uma sequência aleatória simplesmente não existe! Portanto, iniciemos com a primeira e menos restritiva afirmação de Lehmer e tentemos torná-la mais precisa. O que realmente queremos é uma pequena lista de propriedades matemáticas, cada uma delas satisfeita por nossas noções intuitivas de uma sequência aleatória; além disso, a lista precisa ser completa o bastante para que qualquer sequência que a satisfaça possa ser considerada aleatória %\cite{Knuth:98}.
    
  \subsection{Histórico} %Simulação física, Von Neumann, Congruenciais Lineares, etc
  \subsection{Geradores disponíveis no R}
    \begin{itemize}
     \item a
     \item b
     \item c
    \end{itemize}
\section{Verificação clássica das propriedades dos geradores} 
  \subsection{Repetibilidade, portabilidade, eficiência computacional}
%   \subsection{Repetibilidade, portabilidade, eficiência computacional} 
  \subsection{Testes}
  Seja $\bm X = (X_1, X_n)$ uma amostra a respeito da qual temos uma conjectura que queremos verificar.
Essa conjectura é a respeito dos parâmetros que caracterizam a distribuição da amostra, ou a respeito de parâmetros que caracterizam a distribuição de atributos relacionados à distribuição da amostra.
Chamaremos ``hipótese nula'' àquela que convimos em não rejeitar a não ser que obtenhamos suficiente evidência para isso; a denotaremos $H_0$.
Por vezes precisaremos da ``hipótese alternativa'', que denotaremos $H_1$.

Classicamente, um teste de hipótese se baseia em uma estatística de teste $T$ que depende exclusivamente da amostra $\bm X$, isto é, $T(\bm X)$, e é construída de tal forma que adota valores ``pequenos'' sob $H_0$ e ``cresce'' conforme ``se afasta'' de $H_0$.
Idealmente, conhecemos a distribuição de $T$ sob a hipótese nula e, com isso, somos capazes de aferir a probabilidade de observarmos valores ``grandes'' mesmo sob $H_0$.
Definimos, assim, o $p$-valor do teste baseado em $T(\bm X)$ para o valor observado $\eta$ como $\Pr_{H_0}(T(\bm X) \geq \eta)$.
O procedimento básico consiste em rejeitar a hipótese nula ao nível de significância $100(1-\alpha)\%$ se o $p$-valor for inferior a $\alpha$, e em não rejeitá-la caso contrário.
Mais modernamente, não se fala em ``rejeição'', reporta-se o $p$-valor, deixando a decisão para o leitor. Desta forma, chamaremos de ``valor crítico'' o conjunto de valores, definidos pelo leitor tais que, quando assumidos pela estatística de teste $T$ levam à rejeição da hipótese, nula $H_0$. 
% De forma análoga, utilizaremos o termo ``nível de significância'' como a probabilidade máxima de $\alpha$ que nos leve a não rejeitar $H_0$ e acima da qual rejeita-se $H_0$, ou seja a probabilidade de rejeitar $H_0$ quando a mesma é verdadeira.

Diversos testes foram desenvolvidos ao longo do tempo com o objetivo de testar a aleatoriedade de sequências de números.
Como ``aleatoriedade'' é uma noção vaga, cada teste procura identificar uma ou algumas falhas dos dados.
Por esse motivo é que há classes ou conjuntos de testes que, aplicados de forma criteriosa, permitem aferir o quanto uma sequência se afasta da hipótese de aleatoriedade.
A partir dessa análise, pode se ter uma idea do comportamento global do gerador que a produziu.

Sob a conjectura de aleatoriedade, cada estatística de teste $T$ tem uma distribuição, que pode ser determinada ou de forma exata ou de forma aproximada, mas sempre precisa ser conhecida.
Com ela é possível informar o $p$-valor de uma determinada amostra.

% =============================================================================================================================  
%   A metodologia adotada para testar Geradores de Números Pseudoaleatórios é baseada em teste de hipóteses. Um teste de hipóteses 
%   é um procedimento para determinar se uma afirmação sobre uma característica de uma população é coerente. Neste caso, o teste envolve determinar quando uma específica sequência de zeros e uns é aleatória. Praticamente, apenas uma amostra da sequência de saída do PRNG é submetida a vários testes estatísticos.
%   A tabela \ref{Tab:HipoTest} lista algumas terminologias associadas com o teste de hipóteses.
%   \begin{table}[h]
%   \caption{Teste de Hipóteses}
%   \begin{center}
%     \begin{tabular}{c|c}
% 	\textbf{Termo} & \textbf{Definição}\\
% 	\hline
% 	\texttt{Estatística de Teste} & \texttt{}\\
% 	\hline
% 	\texttt{Hipótese Nula} & \texttt{}\\
% 	\hline
% 	\texttt{Hipótese Alternativa} & \texttt{}\\
% 	\hline
% 	\texttt{Nível de Significancia} & \texttt{}\\
% 	\hline
% 	\texttt{Erro Tipo I} & \texttt{}\\
% 	\hline
% 	\texttt{Erro Tipo II} & \texttt{}\\
% 	\hline
% 	\texttt{Intervalo de Confiança} & \texttt{}\\
% 	\hline
% 	\texttt{p-valor} & \texttt{}\\
% 	\hline
% 	\texttt{Valor Crítico} & \texttt{}
% 	\label{Tab:HipoTest}
%     \end{tabular}
%   \end{center}
% \end{table}
% =============================================================================================================================  
  
  
% ############################################################################################################  
%   Vários testes estatísticos podem ser aplicados a uma sequência na tentativa de compará-la e avaliá-la como uma sequência verdadeiramente aleatória. A aleatoriedade é uma propriedade probabilística; isto é, as propriedades de uma sequência aleatória podem ser caracterizadas e descritas em termos de probabilidades. O resultado provável de testes estatísticos, quando aplicados a uma sequência verdadeiramente aleatória, é conhecido a priori e pode ser descrito em termos de probabilidades. Existe um número infinito de possíveis testes estatísticos, cada avaliação da presença ou ausência de um padrão, que, se for detectado, indica que a sequência não é aleatória. Por haver tantos testes para julgar se uma seqüência é aleatória ou não, nenhum conjunto finito específico de testes é considerado completo. Além disso, os resultados dos testes estatísticos devem ser interpretados com algum cuidado e cautela para evitar conclusões incorretas sobre um gerador específico. Um teste estatístico é formulado para testar a hipótese nula específica ($H_0$). Para efeitos do presente documento, a hipótese nula sob teste é de que a sequência a ser testada é aleatória. Associada a esta hipótese nula está a hipótese alternativa ($H_1$), a qual, para este documento, é de que a sequência não é aleatória. Para cada ensaio foi aplicada uma decisão ou conclusão que falha em rejeitar ou rejeita a hipótese nula, isto é, se o gerador estiver (ou não) produzindo valores aleatórios, com base na sequência que foi produzida. Para cada teste, uma estatística de aleatoriedade relevante deve ser escolhida e utilizada para determinar a falha em rejeitar ou rejeição da hipótese de nulidade. De acordo com uma hipótese de aleatoriedade, tal estatística tem uma distribuição de valores possíveis. A distribuição referencial teórica desta estatística sob a hipótese nula é determinado por métodos matemáticos. A partir desta distribuição de referência, um valor crítico é determinado (normalmente, este valor está distante, nas caudas da distribuição, ou seja, para fora no ponto 99\%). Durante um teste, um valor estatístico do ensaio é calculado sobre os dados (a seqüência que está sendo testada). Este valor estatístico do ensaio é comparado com o valor crítico. Se o valor da estatística de teste excede o valor crítico, a hipótese nula de aleatoriedade é rejeitada. Caso contrário, a hipótese nula (a hipótese de aleatoriedade) não é rejeitada (ou seja, a hipótese é aceito). Na prática, a razão pela qual as hipóteses estatísticas funcionam é que a distribuição de referência e o valor crítico são dependentes e gerados, pressupondo-se a ocorrência de aleatoriedade. Se a suposição de aleatoriedade é, de fato, verdadeira para os dados que se têem, em seguida, o valor calculado resultante estatística sobre os dados de teste terão uma probabilidade muito baixa (por exemplo, de 0,01 \%) de exceder o valor crítico. Por outro lado, se o valor calculado teste estatístico não exceda o valor crítico (isto é, se o evento de baixa probabilidade de ocorrer de fato), em seguida, a partir de um ponto de testes de hipóteses de vista estatístico, o evento baixa probabilidade deve ocorrer não naturalmente. Portanto, quando o valor de teste estatística calculada excede o valor crítico, a conclusão é feita de que a suposição original da aleatoriedade é suspeito ou com defeito. Neste caso, o teste de hipótese estatística leva as seguintes conclusões: falhar em rejeitar $H_0$ (aleatoriedade) e aceito $H_1$ (não-aleatoriedade).
%   Teste de hipóteses de Estatística é um procedimento conclusão que tem dois resultados possíveis, Falhar em rejeitar $H_0$ (os dados são aleatórios) ou aceitar $H_1$ (os dados não são aleatórios). A tabela \ref{Tab:HipoTest} relaciona o verdadeiro estado (desconhecido) dos dados em questão para a conclusão a que chegou usando o procedimento de teste.
%   
%   \begin{table}[h]
%   \caption{Teste de Hipóteses}
%   \begin{center}
%     \begin{tabular}{c|c|c}
% 	\textbf{Real Situação} & \textbf{Falhe em Rejeitar $H_0$} & \textbf{Aceite $H_1$ (Rejeite $H_0$)}\\
% 	\hline
% 	\texttt{Dados são aleatórios $H_0$ verdadeiro} & \texttt{Sem erro} & \texttt{Erro tipo I}\\
% 	\hline
% 	\texttt{Dados não são aleatórios $H_1$ verdadeiro} & \texttt{Erro tipo II} & \texttt{Sem erro}
% 	\label{Tab:HipoTest}
%     \end{tabular}
%   \end{center}
% \end{table}
%   ###########################################################################################
% If the data is, in truth, random, then a conclusion to reject the null hypothesis (i.e., conclude that the data is non-random) will occur a small percentage of the time. This conclusion is called a Type I error. If the data is, in truth, non-random, then a conclusion to accept the null hypothesis (i.e., conclude that the data is actually random) is called a Type II error. The conclusions to accept H0 when the data is really random, and to reject H0 when the data is non-random, are correct. 
% 
% The probability of a Type I error is often called the level of significance of the test. This probability can be set prior to a test and is denoted as α. For the test, α is the probability that the test will indicate that the sequence is not random when it really is random. That is, a sequence appears to have non-random properties even when a “good” generator produced the sequence. Common values of α in cryptography are about 0.01. The probability of a Type II error is denoted as β. For the test, β is the probability that the test will indicate that the sequence is random when it is not; that is, a “bad” generator produced a sequence that appears to have random properties. Unlike α, β is not a fixed value. β can take on many different values because there are an infinite number of ways that a data stream can be non-random, and each different way yields a different β. The calculation of the Type II error β is more difficult than the calculation of α because of the many possible types of non-randomness. One of the primary goals of the following tests is to minimize the probability of a Type II error, i.e., to minimize the probability of accepting a sequence being produced by a generator as good when the generator was actually bad. The probabilities α and β are related to each other and to the size n of the tested sequence in such a way that if two of them are specified, the third value is automatically determined. Practitioners usually select a sample size n and a value for α (the probability of a Type I error – the level of significance). Then a critical point for a given statistic is selected that will produce the smallest β (the probability of a Type II error). That is, a suitable sample size is selected along with an acceptable probability of deciding that a bad generator has produced the sequence when it really is random. Then the cutoff point for acceptability is chosen such that the probability of falsely accepting a sequence as random has the smallest possible value. Each test is based on a calculated test statistic value, which is a function of the data. If the test statistic value is S and the critical value is t, then the Type I error probability is P(S > t || Ho is true) = P(reject Ho | H0 is true), and the Type II error probability is P(S ≤ t || H0 is false) = P(accept H0 | H0 is false). The test statistic is used to calculate a P-value that summarizes the strength of the evidence against the null hypothesis. For these tests, each P-value is the probability that a perfect random number generator would have produced a sequence less random than the sequence that was tested, given the kind of nonrandomness assessed by the test. If a P-value for a test is determined to be equal to 1, then the sequence appears to have perfect randomness. A P-value of zero indicates that the sequence appears to be completely non-random. A significance level (α) can be chosen for the tests. If P-value ≥ α, then the null hypothesis is accepted; i.e., the sequence appears to be random. If P-value < α, then the null hypothesis is rejected; i.e., the sequence appears to be non-random. The parameter α denotes the probability of the Type I error. Typically, α is chosen in the range [0.001, 0.01]. 

% \begin{itemize}
%   \item An α of 0.001 indicates that one would expect one sequence in 1000 sequences to be rejected by the test if the sequence was random. For a P-value ≥ 0.001, a sequence would be considered to be random with a confidence of 99.9\%. For a P-value < 0.001, a sequence would be considered to be nonrandom with a confidence of 99.9\%.
%   \item An α of 0.01 indicates that one would expect 1 sequence in 100 sequences to be rejected. A Pvalue ≥ 0.01 would mean that the sequence would be considered to be random with a confidence of 99\%. A P-value < 0.01 would mean that the conclusion was that the sequence is non-random with a confidence of 99\%.
% \end{itemize}
% For the examples in this document, α has been chosen to be 0.01. Note that, in many cases, the parameters in the examples do not conform to the recommended values; the examples are for illustrative purposes only.
%   
  \subsection{Testes anterior}
  \subsection{Testes Diehard}
  
  \subsection{Testes NIST}
  Fundado em 1991, o NIST (Instituto Nacional de Padrões e Tecnologia) é uma agência não regulatória do Departamento de Comércio dos Estados Unidos da América (EUA) que tem por missão promover a inovação e a competitividade nos EUA através da ciência de medidas, padrões e tecnologia de forma a alavancar a segurança econômica e melhorar a qualidade de vida do povo americano.
  A Divisão de Segurança de Computadores (CSD) e o Centro de Pesquisa em Segurança Computacional (CSRC) facilitam a ampla disseminação de práticas e ferramentas de segurança da informação, provendo recursos para a definição de padrões além de identificar recursos de segurança na web para suportar usuários na industria, governo e academia. CSRC é o portal de acesso primário para se ter acesso às publicações de segurança de computadores, padrões e instruções, além de outras informações relacionadas a segurança.
  Desde 1997, o Grupo de Trabalho Técnico em Geração de Números Aleatórios (RNG-TWG) tem trabalhado no desenvolvimento de uma bateria de testes estatísticos apropriados para a avaliação de geradores de números aleatórios e pseudoaleatórios utilizados em aplicações criptográficas. 
  Os principais objetivos do grupo são:
  \begin{itemize}
   \item Desenvolvimento de uma bateria de testes estatísticos para detectar não aleatoriedade em sequencias binárias construidas através de geradores de números aleatórios e pseudoaleatórios utilizados em aplicações criptográficas;
   \item Produzir documentação e uma implementação em software destes testes;
   \item Prover auxílio no uso e aplicação destes testes.
  \end{itemize}
  Um total de quinze testes estatísticos foram desenvolvidos, implementados e avaliados. A seguir fazemos um breve descritivo acerca dos testes.
  
  %   Founded in 1901, NIST is a non-regulatory federal agency within the U.S. Department of Commerce. NIST's mission is to promote U.S. innovation and industrial competitiveness by advancing measurement science, standards, and technology in ways that enhance economic security and improve our quality of life.
% The Computer Security Division's (CSD) Computer Security Resource Center (CSRC) facilitates broad sharing of information security tools and practices, provides a resource for information security standards and guidelines, and identifies key security web resources to support users in industry, government, and academia. CSRC is the primary gateway for gaining access to NIST computer security publications, standards, and guidelines plus other useful security-related information.
% Since 1997, the Random Number Generation Technical Working Group (RNG-TWG) has been working on developing a battery of statistical tests suitable in the evaluation of random number generators and pseudo-random number generators used in cryptographic applications. Currently, we are finalizing the documentation and software in preparation for public release. An excerpt from the document is provided below.
%   The three primary goals were: (a) to develop a battery of statistical tests to detect non-randomness  in binary sequences constructed using random number generators and pseudo-random number generators utilized in cryptographic applications, (b) to produce documentation and a software implementation of these tests, and (c) to provide guidance in the use and application of these tests.
% A total of fifteen statistical tests were developed, implemented and evaluated. The following describes each of the tests.
  
  \begin{itemize}
   \item \textbf{Frequency (Monobits) Test} - O foco do teste está na proporção de $zeros$ e $uns$ em toda a sequência. O propósito deste teste é determinar em que momento o número de $zeros$ e $uns$ numa sequência é aproximadamente o mesmo como é o esperado para uma sequência realmente aleatória. O teste avalia a proximidade da porção de $uns$ a $½$, ou seja, o número de $zeros$ e $uns$ numa sequência deve ser o mesmo.
%    The focus of the test is the proportion of zeroes and ones for the entire sequence. The purpose of this test is to determine whether that number of ones and zeros in a sequence are approximately the same as would be expected for a truly random sequence. The test assesses the closeness of the fraction of ones to ½, that is, the number of ones and zeroes in a sequence should be about the same.
   \item \textbf{Test For Frequency Within A Block} - O teste avalia a proporção de $zeros$ e $uns$ em blocos de M bits. O propósito principal deste teste é determinar se a frequência de $uns$ em um bloco de $M$ bits é aproximadamente $M/2$.
%    The focus of the test is the proportion of zeroes and ones within M-bit blocks. The purpose of this test is to determine whether the frequency of ones is an M-bit block is approximately M/2.
   \item \textbf{Runs Test} -  Dada uma sequência ininterrupta de zeros ou de $uns$, chamaremos esta sequência de ``rodada'' e de ``k'' tamanho da sequência. O objetivo do teste é determinar a proporção de rodadas de zeros e $uns$ de diversos tamanhos ``k'' necessária para caracterizar uma sequência com aleatória. Em particular, este teste determina quando a oscilação enter estas substrings é muito rápida ou muito lenta.
%    The focus of this test is the total number of zero and one runs in the entire sequence, where a run is an uninterrupted sequence of identical bits. A run of length k means that a run consists of exactly k identical bits and is bounded before and after with a bit of the opposite value. The purpose of the runs test is to determine whether the number of runs of ones and zeros of various lengths is as expected for a random sequence. In particular, this test determines whether the oscillation between such substrings is too fast or too slow.
   \item \textbf{Test For The Longest Run Of Ones In A Block} - O teste tem como objetivo determinar quando o comprimento da maior rodada de $uns$ na sequência testada é equivalente ao tamanho da maior rodada esperada em uma sequência aleatória. Note que uma irregularidade no tamanho esperado no valor da maior rodada de $uns$ implica que também há uma irregularidade no tamanho esperado da rodada de $zeros$ mais longa.
%    The focus of the test is the longest run of ones within M-bit blocks. The purpose of this test is to determine whether the length of the longest run of ones within the tested sequence is consistent with the length of the longest run of ones that would be expected in a random sequence. Note that an irregularity in the expected length of the longest run of ones implies that there is also an irregularity in the expected length of the longest run of zeroes. Long runs of zeroes were not evaluated separately due to a concern about statistical independence among the tests.
   \item \textbf{Random Binary Matrix Rank Test} - O teste avalia a categoria das submatrizes disjuntas da sequência toda. O objetivo do teste é verificar a ocorrência de dependência linear entre substrings de tamanho fixo da sequência original.
%    The focus of the test is the rank of disjoint sub-matrices of the entire sequence. The purpose of this test is to check for linear dependence among fixed length substrings of the original sequence.
   \item \textbf{Discrete Fourier Transform (Spectral) Test} - O teste foca nos picos da \texttt{Transformada Rápida de Fourrier} com o propósito de detectar característica periódicas.
%    The focus of this test is the peak heights in the discrete Fast Fourier Transform. The purpose of this test is to detect periodic features (i.e., repetitive patterns that are near each other) in the tested sequence that would indicate a deviation from the assumption of randomness.
   \item \textbf{Non-Overlapping (Aperiodic) Template Matching Test} - O teste observa o número de ocorrências de substrings predefinidas com o propósito de rejeitar sequências que possuam muitas ocorrências de um dado padrão aperiódico. Para tal uma janela de $m$ bits é usada para procurar por um padrão específico de "m" bits.
%    The focus of this test is the number of occurrences of pre-defined target substrings. The purpose of this test is to reject sequences that exhibit too many occurrences of a given non-periodic (aperiodic) pattern. For this test and for the Overlapping Template Matching test, an m-bit window is used to search for a specific m-bit pattern. If the pattern is not found, the window slides one bit position. For this test, when the pattern is found, the window is reset to the bit after the found pattern, and the search resumes.
   \item \textbf{Overlapping (Periodic) Template Matching Test} - O teste, assim com o o anterior, procura por substrings predefinidas de rodadas de $uns$ com um dado tamanho. O objetivo do teste é rejeitar sequências que mostrem um desvio do número esperado de $uns$ de um dado tamanho. Note que, quando há um desvio no número de $uns$, este desvio também ocorre com o número de $zeros$. Da mesma forma que o teste anterior, uma janela de $m$ bits é usada para detectar a presença de padrões.
%    The focus of this test is the number of pre-defined target substrings. The purpose of this test is to reject sequences that show deviations from the expected number of runs of ones of a given length. Note that when there is a deviation from the expected number of ones of a given length, there is also a deviation in the runs of zeroes. Runs of zeroes were not evaluated separately due to a concern about statistical independence among the tests. For this test and for the Non-overlapping Template Matching test, an m-bit window is used to search for a specific m-bit pattern. If the pattern is not found, the window slides one bit position. For this test, when the pattern is found, the window again slides one bit, and the search is resumed.
   \item \textbf{Maurer's Universal Statistical Test} - O teste observa o número de bits entre padrões casados com o objetivo de detectar ou não se a sequência pode ser significativamente comprimida sem a perda de informação. Uma sequência que pode ser totalmente comprimida é considerada como não aleatória.
%    The focus of this test is the number of bits between matching patterns. The purpose of the test is to detect whether or not the sequence can be significantly compressed without loss of information. An overly compressible sequence is considered to be non-random.
   \item \textbf{Linear Complexity Test} - O teste focaliza no tamanho de um registro gerador de informação com o objetivo de determinar quando ou não a sequência é complexa o suficiente para ser considerada aleatória. Sequências aleatórias são caracterizadas por um registro gerador de informação longo.
%    The focus of this test is the length of a generating feedback register. The purpose of this test is to determine whether or not the sequence is complex enough to be considered random. Random sequences are characterized by a longer feedback register. A short feedback register implies non-randomness.
   \item \textbf{Serial Test} - O teste detem o foco sobre a frequência de cada bit e de todos os padrões sobrepostos de $m$ bits em toda a sequência, com o propósito de determinar quando o número de ocorrências de padrões sobrepostos de 2m $m$ bits é o mesmo do esperado para sequências aleatórias, sabendo que o padrão pode ser sobreposto.
%    The focus of this test is the frequency of each and every overlapping m-bit pattern across the entire sequence. The purpose of this test is to determine whether the number of occurrences of the 2m m-bit overlapping patterns is approximately the same as would be expected for a random sequence. The pattern can overlap.
   \item \textbf{Approximate Entropy Test} - O teste se detém na frequência de cada um dos padrões sobrepostos de $m$ bits com o objetivo de comparar a frequência de dois blocos sobrepostos de tamanhos consecutivos/adjacentes ($m$ e $m+1$) com os valores esperados para uma sequência aleatória.
%    The focus of this test is the frequency of each and every overlapping m-bit pattern. The purpose of the test is to compare the frequency of overlapping blocks of two consecutive/adjacent lengths (m and m+1) against the expected result for a random sequence.
   \item \textbf{Cumulative Sum (Cusum) Test} - O teste verifica a distância máxima do ``passeio aleatório'' definido pela soma dos dígitos ajustados ($-1$, $+1$) na sequência com o objetivo de determinar quando a soma cumulativa da sequência parcial que ocorre nas sequências testadas é muito grande ou muito pequeno em relação ao comportamento esperado para sequências aleatórias. Esta sequência cumulativa pode ser considerada como um ``passeio aleatório''. Para uma sequência aleatória, o ``passeio aleatório'' deve ser próximo a $zero$ e para sequências não aleatórias a excursão máxima do ``passeio aleatório'' se distancia de zero e tende a ser grande.
%    The focus of this test is the maximal excursion (from zero) of the random walk defined by the cumulative sum of adjusted (-1, +1) digits in the sequence. The purpose of the test is to determine whether the cumulative sum of the partial sequences occurring in the tested sequence is too large or too small relative to the expected behavior of that cumulative sum for random sequences. This cumulative sum may be considered as a random walk. For a random sequence, the random walk should be near zero. For non-random sequences, the excursions of this random walk away from zero will be too large.
   \item \textbf{Random Excursions Test} - O teste verifica o número de ciclos que possuem exatamente $K$ visitas em uma soma cumulativa do tipo ``passeio aleatório''. A soma cumulativa é encontrada se a soma parcial das sequências de ($0$, $1$) está ajustada a ($-1$, $+1$). Uma ``jornada aleatória'' de um ``passeio aleatório'' consiste em uma sequência de $n$ passos de tamanho unitário tomados aleatoriamente iniciando e terminando na origem. O objetivo deste teste é determinar se o número de visitas a um estado em um ``passeio aleatório'' excede o esperado para uma sequência aleatória.
%    The focus of this test is the number of cycles having exactly K visits in a cumulative sum random walk. The cumulative sum random walk is found if partial sums of the (0,1) sequence are adjusted to (-1, +1). A random excursion of a random walk consists of a sequence of n steps of unit length taken at random that begin at and return to the origin. The purpose of this test is to determine if the number of visits to a state within a random walk exceeds what one would expect for a random sequence.
   \item \textbf{Random Excursions Variant Test} - O teste verifica o número de vezes que um estado em particular ocorreu na soma cumulativa de um ``passeio aleatório'' com o objetivo de detectar desvios do número esperado de ocorrências de vários estados do ``passeio aleatório''.
%    The focus of this test is the number of times that a particular state occurs in a cumulative sum random walk. The purpose of this test is to detect deviations from the expected number of occurrences of various states in the random walk.
  \end{itemize}

  \subsection{Testes Dieharder}
  Como substituta à suíte de testes anteriores, RGB reescreveu-os numa linguagem portável como C e acrescentou ao conjunto de testes disponíveis no Diehard alguns outros testes do NIST e mais alguns de sua autoria, listados na tabela \ref{Tab:DieharderTests} e explicados abaixo.
  
\begin{table}[h]
  \caption{Testes disponíveis no Dieharder}
  \begin{center}
    \begin{tabular}{l|l|c}
	\hline
	\textbf{Seq} & \textbf{Nome} & \textbf{ID}\\
	\hline
	\texttt{1} & \texttt{diehard birthdays} & \texttt{0}\\
	\hline
	\texttt{2} & \texttt{diehard operm5} & \texttt{1}\\
	\hline
	\texttt{3} & \texttt{diehard rank 32x32} & \texttt{2}\\
	\hline
	\texttt{4} & \texttt{diehardrank 6x8} & \texttt{3}\\
	\hline
	\texttt{5} & \texttt{diehard bitstream} & \texttt{4}\\
	\hline
	\texttt{6} & \texttt{diehard opso} & \texttt{5}\\
	\hline
	\texttt{7} & \texttt{diehard oqso} & \texttt{6}\\
	\hline
	\texttt{8} & \texttt{diehard dna} & \texttt{7}\\
	\hline
	\texttt{9} & \texttt{diehard count 1s stream} & \texttt{8}\\
	\hline
	\texttt{10} & \texttt{diehard count 1s byte} & \texttt{9}\\
	\hline
	\texttt{11} & \texttt{diehard parking lot} & \texttt{10}\\
	\hline
	\texttt{12} & \texttt{diehard 2dsphere} & \texttt{11}\\
	\hline
	\texttt{13} & \texttt{diehard 3dsphere} & \texttt{12}\\
	\hline
	\texttt{14} & \texttt{diehard squeeze} & \texttt{13}\\
	\hline
	\texttt{15} & \texttt{diehard sums} & \texttt{14}\\
	\hline
	\texttt{16} & \texttt{diehard runs} & \texttt{15}\\
	\hline
	\texttt{17} & \texttt{diehard craps} & \texttt{16}\\
	\hline
	\texttt{18} & \texttt{marsaglia tsang gcd} & \texttt{17}\\
	\hline
	\texttt{19} & \texttt{sts monobit} & \texttt{100}\\
	\hline
	\texttt{20} & \texttt{sts runs} & \texttt{101}\\
	\hline
	\texttt{21} & \texttt{sts serial} & \texttt{102}\\
	\hline
	\texttt{22} & \texttt{rgb bitdist} & \texttt{200}\\
	\hline
	\texttt{23} & \texttt{rgb minimum distance} & \texttt{201}\\
	\hline
	\texttt{24} & \texttt{rgb permutations} & \texttt{202}\\
	\hline
	\texttt{25} & \texttt{rgb lagged sum} & \texttt{203}\\
	\hline
	\texttt{26} & \texttt{rgb kstest test} & \texttt{204}\\
	\hline
	\texttt{27} & \texttt{dab bytedistrib} & \texttt{205}\\
	\hline
	\texttt{28} & \texttt{dab dct} & \texttt{206}\\
	\hline
	\texttt{29} & \texttt{dab filltree} & \texttt{207}\\
	\hline
	\texttt{30} & \texttt{dab filltree2} & \texttt{208}\\
	\hline
	\texttt{31} & \texttt{dab monobit2} & \texttt{209}
% 	\hline
	\label{Tab:DieharderTests}
    \end{tabular}
  \end{center}
\end{table}
  
 \begin{itemize}
   \item \textbf{``Birthdays'' test (modificado). Id(0)} -  Cada teste determina o número de intervalos que combinam de 512 ``aniversários'' (por padrão) tomados num ``ano'' fictício de 24 bits (por padrão). Este processo é repetido (por padrão) 100 vezes e o resultado é acumulado em um histograma. Intervalos repetidos podem ser distribuidos em uma distribuição Poisson se o gerador em questão for aleatório o suficiente, e em uma Chi Quadrado com o p-valor avaliado relativamente à hipótese nula. É recomendado rodar este teste próximo ou com exatamente 100 amostras por p-valor com \texttt{-t 100}. Dois parametros adicionais foram incluidos. No Diehard, nms=512, porém isto pode ser variado e todas as fórmulas de Marsaglia continuam a funcionar. Pode ser ajustado para valores diferentes com \texttt{-x nmsvalue}. Similarmente, o parâmetro \texttt{nbits}pode ser 24, mas podemos fazê-lo assumir qualquer valor desde que seja menor ou igual a \texttt{rmax\_bits = 32}. E pode ser atribuido qualquer valor com o parâmetro \texttt{-y nbits}. Ambos são padrão para os valores do Diehard se as opções \texttt{-x e -y} não forem utilizadas.
   
   \item \textbf{Diehard Overlapping 5-Permutations Test. Id(1)} - O teste procura por uma sequência aleatória de $10^6$ inteiros. Cada conjunto de cinco inteiros consecutivos pode estar em um dos $120$ estados, para as $5!$ possíveis combinações de cinco números. Portanto, cada um dos $5^{o}$, $6^{o}$, $7^{o}$, \dots fornecem um estado. Assim, como milhares de transições de estado são observadas, contadores cumulativos são gerados a partir do número de ocorrências de cada estado. Logo, a forma quadrática na inveresa fraca da matriz de covariância $120\times120$ produz um teste equivalente ao do teste da taxa de verossimilhança, onde as 120 células vêem da distribuição normal (assintoticamente) especificada com a específica matriz de covariância $120\times120$ (com rank 99). Esta versão usa $1.000.000$ de inteiros, duas vezes. Note que o Dieharder executa o teste 100 vezes por padrão e não 2.
%    This is the OPERM5 test.  It looks at a sequence of one million 32-bit random integers.  Each set of five consecutive integers can be in one of 120 states, for the 5! possible orderings of five numbers.  Thus the 5th, 6th, 7th, \dots numbers each provide a state. As many thousands of state transitions are observed,  cumulative counts are made of the number of occurences of each state.  Then the quadratic form in the weak inverse of the 120x120 covariance matrix yields a test equivalent to the likelihood ratio test that the 120 cell counts came from the specified (asymptotically) normal distribution with the specified 120x120 covariance matrix (with rank 99).  This version uses 1.000.000 integers, twice. Note that Dieharder runs the test 100 times, not twice, by default.
   
   \item \textbf{Diehard 32x32 Binary Rank Test. Id(2)} - Neste teste uma matriz binária $32\times32$ é formada com cada linha contendo um inteiro aleatório de 32 bits. O rank é determinado e pode assumir valores de $0$ a $32$, ranks menores de 29 são raros e suas ocorrências são acumuladas no rank 29. Os ranks são calculados para as $40.000$ matrizes e um teste chi quadrado é realizado nas contagens para os ranks $32, 31, 30 e \leqslant 29$. Como de costume na bateria de testes, o teste é repetido e um teste KS (Kolmogorov Smirnov) é aplicado aos $p-valores$ obtidos afim de verificar se eles são uniformes.
%    This is the BINARY RANK TEST for $32\times32$ matrices. A random $32\times32$ binary matrix is formed, each row a 32\-bit random integer. The rank is determined. That rank can be from 0 to 32, ranks less than 29 are rare, and their counts are pooled with those for rank 29.  Ranks are found for $40.000$ such random matrices and a chisquare test is performed on counts for ranks $32, 31, 30 and \leqslant 29$. As always, the test is repeated and a KS test applied to the resulting p \textendash values to verify that they are approximately uniform.

   \item \textbf{Diehard 6x8 Binary Rank Test. Id(3)} - Neste teste cada uma dos $seis$ inteiros aleatórios de $32$ bits do gerador submetido ao teste tem um $byte$ escolhido e os $seis$ bits resultantes formam uma matriz binária $6\times8$ cujo rank é determindado. Este rank pode ser de $0$ a $6$, porém ranks $0, 1, 2, 3$ são raros e seus valores são armazendados juntamente daqueles de rank $4$. São encontrados os ranks para $100.000$ matrizes aleatórias e um testes chi quadrado é aplicado aos contadores para os ranks $6, 5 e \leqslant4$. Como sempre, o teste é repetido e um teste KS é aplicado ao $p-valor$ resultante para verificar se eles são uniformmes.
%    This is the BINARY RANK TEST for $6\times8$ matrices.  From each of six random 32\-bit integers from the generator under test, a specified byte is chosen, and the resulting six bytes form a $6\times8$ binary matrix whose rank is determined.  That rank can be from 0 to 6, but ranks $0, 1, 2, 3$ are rare; their counts are pooled with those for rank 4. Ranks are found for $100.000$ random matrices, and a chi-square test is performed on counts for ranks $6, 5 and \leqslant4$. As always, the test is repeated and a KS test applied to the resulting p \textendash values to verify that they are approximately uniform.
   
   \item \textbf{Diehard Bitstream Test. Id(4)} - O arquivo sob teste é visto como um fluxo de bits. Chamaremo-os $b_1$,$b_2$,$\dots$ . Considere um alfabeto de duas ``letras'', $0$ e $1$ e pense no fluxo de bits como uma sucessão de ``palavras'' de $20$ letras com sobreposição. Então, a primeira palavra é $b_1$ $b_2$ $\dots$ $b_{20}$, o segundo é $b_2$ $b_3$ $\dots$ $b_{21}$ e assim por diante. O teste conta o número de palavras de $20$ letras ou $20$ bits ausentes numa string de $2^{(21)}$ sobrepondo palavras de $21$ letras. Dado que existem $2^{20}$ possíveis palavras de $20$ letras, para uma string realmente aleatória de $2^{21}+19$ bits, o número de palavras ausentes ``j'' deve ser (ou bem próximo de) normalmente distribuido com média $141.909$ e $\sigma = 428$. Logo, $(j-141909)/428$ deve ser a variação (z score) que nos leva a um ($p-value$) uniforme $[0.1)$. O teste é repetido vinte vezes. Note que o teste é repetido 100 vezes por padrão no $dieharder$, mas o tamanho da amostra é fixo ($t-samples$ não devem/podem ser modificados do padrão), neste teste $\sigma$ requer o uso de amostras sobrepostas, e tais amostras não são independentes. Caso queira usar a versão sem sobreposição do teste, $\sigma = 290$ precisa ser utilizado.
%    The file under test is viewed as a stream of bits. Call them  $b_1$,$b_2$,\dots  .  Consider an alphabet with two ``letters'', 0 and 1 and think of the stream of bits as a succession of 20-letter ``words'', overlapping.  Thus the first word is $b_1$ $b_2$\dots$b_{20}$, the second is $b_2$ $b_3$\dots$b_{21}$, and so on.  The bitstream test counts the number of missing 20\-letter (20\-bit) words in a string of 2(21) overlapping 20\-letter words.  There are $2^{20}$ possible 20 letter words.  For a truly random string of $2^{21}+19$ bits, the number of missing words j should be (very close to) normally distributed with mean $141.909$ and sigma 428. Thus (j-141909)/428 should be a standard normal variate (z score) that leads to a uniform [0,1) p\-value. The test is repeated twenty times.
%    NOTE WELL!
%    The test is repeated 100 times by default in dieharder, but the size of the sample is fixed (tsamples cannot/should not be varied from the  default).  The sigma of this test REQUIRES the use of overlapping samples, and overlapping samples are not independent. If one uses the non-overlapping version of this test, sigma = 290 is used instead, smaller because now there are $2^{21}$ INDEPENDENT samples.
   
   \item \textbf{Diehard Overlapping Pairs Sparse Occupance (OPSO). Id (5)} - O teste considera palavras de $2$ letras em um alfabeto de $1024$ letras, cada letra é determinada por $10$ bits específicos em uma sequência inteira de $32$ bits a ser testada. O mesmo gera $2^{21}$ palavras (sobrepostas) de $2$ bits (de um total de $2^{21}+1$ ``teclas pressionadas'' e conta o número de palavras ausentes, ou seja, palavras de $2$ letras que não aparecem em toda a sequência. Esta contagem precisa ser muito próxima de normalmente distribuida com média $141909$, $\sigma 290$. Logo $(ausentes-141909)/290$ deve ser a variação padrão normal. O teste toma 32 bits do arquivo a ser testado por vez e usa um conjunto específico de dez bits consecutivos. Então reinicia o arquivo para os próximos dez bits e assim por diante. Note que $2^{21}=2097152$, $tsamples$ não podem ser variados.
%    The OPSO test considers 2\-letter words from an alphabet of 1024 letters.  Each letter is determined by a specified ten bits from a 32\-bit integer in the sequence to be tested. OPSO generates  $2^{21}$ (overlapping) 2\-letter words (from $2^{21}+1$ ``keystrokes'')  and counts the number of missing words that is 2\-letter words which do not appear in the entire sequence. That count should be very close to normally distributed with mean $141.909, \sigma290$. Thus $(missingwrds\-141909)\diagup290$ should be a standard normal variable. The OPSO test takes 32 bits at a time from the test file and uses a designated set of ten consecutive bits. It then restarts the file for the next designated 10 bits, and so on. Note $2^{21} = 2097152$, tsamples cannot be varied.
   
   \item \textbf{Diehard Overlapping Quadruples Sparce Occupancy (OQSO) Test. Id(6)} - Similarmente ao teste anterior, exceto pelo fato de considerar palavras de $4$ letras em um alfabeto de 32 letras, cada letra determinada por uma determinada string de $5$ bits consecutivos do arquivo testado. O número médio de palavras ausentes numa sequência de $2^{21}$ palavras de $4$ letras, ($2^{21}+3$ ``teclas pressionadas'') é novamente $141909$, com $\sigma=295$. A média é baseada na teoria, $\sigma$ vem de exaustiva simulação. Note que $2^{21}=2097152$, tsamples não podem ser variados.
%    Similar, to OPSO except that it considers 4\-letter words from an alphabet of 32 letters, each letter determined by a designated string of 5 consecutive bits from the test file, elements of which are assumed 32\-bit random integers. The mean number of missing words in a sequence of $2^{21}$ four\-letter words, ( $2^{21}$ + 3 ``keystrokes'' ), is again $141909$, with $\sigma$ = 295. The mean is based on theory, $\sigma$ comes from extensive simulation. Note $2^{21} = 2097152$, tsamples cannot be varied.
   
   \item \textbf{Diehard DNA Test. Id(7)} - O teste considera um alfabeto de $4$ letras \texttt{C,G,A,T}, determinadas por dois bits significativos na sequência de inteiros aleatórios que está sendo testada. Avaliando palavras de $10$ letras, assim como no OPSO e OQSO, existem $2^{20}$ possíveis palavras, e o número médio de palavras faltantes em uma sequência de $2^{21}$ sobrepondo palavras de $10$ letras ($2^{21}+9$ ``teclas pressionadas'') é 141909. O desvio padrão $\sigma=339$ foi determinado assim como para OQSO, por simulação.
%    The DNA test considers an alphabet of 4 letters: \texttt{C,G,A,T}, determined by two designated bits in the sequence of random integers being tested. It considers 10\-letter words, so that as in OPSO and OQSO, there are $2^{20}$ possible words, and the mean number of missing words from a string of $2^{21}$ (over-lapping)  10\-letter words ($2^{21}+9$ ``keystrokes'') is 141909. The standard deviation $\sigma$=339 was determined as for OQSO by simulation. ($\sigma$ for OPSO, $290$, is the true value (to three places), not determined by simulation. Note $2^{21} = 2097152$. Note also that we don't bother with overlapping keystrokes (and sample more rands \- rands are now cheap). 

   \item \textbf{Diehard Count the 1s (stream) (modified) Test. Id(8)} - Neste teste o arquivo avaliado é tratado como um \texttt{stream} de bytes (quatro para cada inteiro de 32 bits). Cada byte pode conter de $0 a 8$ uns, Com probabilidades $1, 8, 28, 56, 70, 56, 28, 8, 1 sobre  256$. Desta forma, deixemos que o stream de bytes forneça uma string de $5$ palavras com sobreposição, onde cada ``letra'' assume os valores $A, B, C, D, E$. As letras são determinadas pela quantidades de ``uns'' em um byte: 0, 1 ou 2 são representados por A, 3 representa B, 4 representa C, 5 representa D e 6, 7 ou 8 representam E. Desta forma, temos 5 teclas com diversas probabilidades ($37,56,70,56,37 s 256$)
%    Consider the file under test as a stream of bytes (four per 32 bit integer).  Each byte can contain from 0 to 8 1's, with probabilities 1,8,28,56,70,56,28,8,1 over 256.  Now let the stream of bytes provide a string of overlapping  5-letter words, each ``letter'' taking values A,B,C,D,E. The letters are determined by the number of 1's in a byte:  0, 1, or 2 yield A, 3 yields B, 4 yields C, 5 yields D and 6, 7 or 8 yield E. Thus we have a monkey at a typewriter hitting five keys with various probabilities (37,56,70,56,37 over 256).  There are $5^{5}$ possible 5\-letter words, and from a string of 256.000 (over-lapping) 5\-letter words, counts are made on the frequencies for each word. The quadratic form in the weak inverse of the covariance matrix of the cell counts provides a chisquare test: Q5-Q4, the difference of the naive Pearson sums of $(OBS-EXP)^2/EXP$ on counts for 5 and 4-letter cell counts.
   
   \item \textbf{Diehard Count the 1s Test (byte) (modified). Id(9)} - This is the COUNT\-THE\-1's TEST for specific bytes. Consider the file under 	test as a stream of 32\-bit integers. From each integer, a specific byte is chosen, say the left\-most: bits 1 to 8. Each byte can contain from 0 to 8 1's, with probabilitie 1, 8, 28, 56, 70, 56, 28, 8, 1 over 256.  Now let the specified bytes from successive integers provide a string of (overlapping) 5\-letter words, each ``letter'' taking values A,B,C,D,E. The letters are determined  by the number of $1's$, in that byte: $0,  1,  or  2 \rightarrow A,  3 \rightarrow B,  4 \rightarrow C,  5 \rightarrow D,  and  6,  7 or  8 \rightarrow E$. Thus we have a monkey at a typewriter hitting five keys with with various probabilities: 37, 56, 70, 56, 37 over 256. There are $5^5$ possible 5\-letter words, and from a string of 256.000 (overlapping) 5\-letter words, counts are made on the frequencies for each word. The quadratic form in the weak inverse of the covariance matrix of the cell counts provides a chisquare test: Q5\-Q4, the difference of the naive Pearson sums of $(OBS-EXP)^2/EXP$ on counts for 5 and 4-letter cell counts. Note: We actually cycle samples over all 0\-31 bit offsets, so that if there is a problem with any particular offset it has a chance of being observed.  One can imagine problems with odd offsets but not even, for example, or only with the offset 7. tsamples and psamples can be freely varied, but you'll likely need $tsamples \gg 100.000$ to have enough to get a reliable kstest result. 

   \item \textbf{Diehard Parking Lot Test (modified). Id(10)} - This tests the distribution of attempts to randomly park a square car of length 1 on a 100x100 parking lot without crashing.  We plot n (number of attempts) versus k (number of attempts that didn't "crash" because the car squares  overlapped and compare to the expected result from a perfectly random set of parking coordinates.  This is, alas, not really known on theoretical grounds so instead we compare to n=12,000 where k should average 3523 with sigma 21.9 and is very close to normally distributed. Thus (k-3523)/21.9 is a standard normal variable, which converted to a uniform p-value, provides input to a KS test with a default 100 samples.
   
   \item \textbf{Diehard Minimum Distance (2d Circle) Test Id(11)} - It does this 100 times: choose $n=8.000$ random points in a square of side 10.000. Find d, the minimum distance between the $(n^2-n)/2$ pairs of points.  If the points are truly independent uniform, then $d^2$, the square of the minimum distance should be (very close to) exponentially distributed with mean $0.995$.  Thus $1-exp(-d^2/0.995)$ should be uniform on $[0,1)$ and a KSTEST on the resulting 100 values serves as a test of uniformity for random points in the square. Test $numbers=0 mod 5$  are printed but the KSTEST is based on the full set of 100 random choices of 8.000 points in the $10.000x10.000$ square. This test uses a fixed number of samples \- tsamples is ignored. It also uses the default value of 100 psamples in the final KS test, for once agreeing precisely with Diehard.
   
   \item \textbf{Diehard 3d Sphere (Minimum Distance) Test. Id(12)} - Choose  4.000 random points in a cube of edge 1.000.  At each point, center a sphere large enough to reach the next closest point. Then the volume of the smallest such sphere is (very close to) exponentially distributed with mean $120\pi/3$. Thus the radius cubed is exponential with mean 30. (The mean is obtained by extensive simulation). The 3DSPHERES test generates 4.000 such spheres 20 times. Each min radius cubed leads to a uniform variable by means of $1-exp(-r^3/30)$, then a KSTEST is done on the 20 p-values. This test ignores tsamples, and runs the usual default 100 psamples to use in the final KS test.
   
   \item \textbf{Diehard Squeeze Test. Id(13)} - Random integers are floated to get uniforms on [0,1). Starting with $k=2^{31}$=2147483647, the test finds j, the number of iterations necessary to reduce k to 1, using the reduction $k = ceiling(k \times U)$, with U provided by floating integers from the file being tested. Such j's are found 100.000 times, then counts for the number of times j was $\leq 6, 7,\dots, 47, \geq 48$ are used to provide a chi\-square test for cell frequencies. 
   
   \item \textbf{Diehard Sums Test Id(14)} - Integers are floated to get a sequence $U(1),U(2),\dots$ of uniform [0,1) variables. Then overlapping sums, $S(1) = U(1)+ \dots + U(100), S2 = U(2)+ \dots +U(101), \dots$ are formed. The S's are virtually normal with a certain covariance matrix.  A linear transformation of the S's converts them to a sequence of independent standard normals, which are converted  to uniform variables for a KSTEST. The p\-values from ten KSTESTs are given still another KSTEST. Comments At this point I think there is rock solid evidence that this test is completely useless in every sense of the word. It is broken, and it is so broken that there is no point in trying to fix it. The problem is that the transformation above is not linear, and doesn't work. Don't use it. For what it is worth, rgb\_lagged\_sums with ntuple 0 tests for exactly the same thing, but scalably and reliably without the complication of overlapping samples and covariance. Use it instead.
   
   \item \textbf{Diehard Runs Test. Id(15)} - This is the RUNS test. It counts runs up, and runs down, in a sequence of uniform [0,1) variables, obtained by floating the 32-bit integers in the specified file. This example    shows how runs are counted:  .123,.357,.789,.425,.224,.416,.95 contains an up-run of length 3, a down-run of length 2 and an  up-run of (at least) 2, depending on the next values.  The     covariance matrices for the runs-up and runs-down are well     known, leading to chisquare tests for quadratic forms in the   weak inverses of the covariance matrices.  Runs are counted    for sequences of length 10.000.  This is done ten times. Then  repeated. In Dieharder sequences of length tsamples = 100000 are used by default, and 100 p-values thus generated are used in a final KS test.
   
   \item \textbf{Diehard Craps Test. Id(16)} - This is the CRAPS TEST. It plays 200.000 games of craps, finds  the number of wins and the number of throws necessary to end  each game.  The number of wins should be (very close to) a normal with mean 200000p and variance 200000p(1-p), with p=244/495.  Throws necessary to complete the game can vary from 1 to infinity, but counts for all > 21 are lumped with 21. A chi-square test is made on the number-of-throws cell counts. Each 32-bit integer from the test file provides the value for the throw of a die, by floating to [0,1), multiplying by 6 and taking 1 plus the integer part of the result.
   
   \item \textbf{Marsaglia and Tsang GCD Test. Id(17)} - $10^7$ tsamples (default) of uint rands u, v are generated and two statistics are generated: their greatest common divisor (GCD) (w) and the number of steps of Euclid's Method required to find it (k). Two tables of frequencies are thus generated - one for the number of times each value for k in the range 0 to 41 (with counts greater than this range lumped in with the endpoints). The other table is the frequency of occurrence of each GCD with k is be distributed approximately binomially, but this is useless for the purposes of performing a stringent test.  Instead four ``good'' RNGs (gfsr4, mt19937\_1999, rndlxs2, taus2) were used to construct a simulated table of high precision probabilities for k (a process that obviously begs the question as to whether or not THESE generators are ``good'' wrt the test). At any rate, they produce very similar tables and pass the test with each other's tables (and are otherwise very different RNGs).  The table of probabilities for the gcd distribution is generated dynamically per test (it is easy to compute).  Chisq tests on both of these binned distributions yield two p\-values per test, and 100 (default) p\-values of each are accumulated and subjected to final KS tests and displayed in a histogram.
   
   \item \textbf{STS Monobit Test. Id(100)} - Very simple. Counts the 1 bits in a long string of random uints. Compares to expected number, generates a p-value directly from erfc().  Very effective at revealing overtly weak generators; Not so good at determining where stronger ones eventually fail.
   
   \item \textbf{STS Runs Test. Id(101)} - Counts the total number of 0 runs + total number of 1 runs across a sample of bits.  Note that a 0 run must begin with 10 and end with 01.  Note that a 1 run must begin with 01 and end with a 10. This test, run on a bitstring with cyclic boundary conditions, is absolutely equivalent to just counting the 01 + 10 bit pairs. It is therefore totally redundant with but not as good as the rgb\_bitdist() test for 2-tuples, which looks beyond the means to the moments, testing an entire histogram  of 00, 01, 10, and 11 counts to see if it is binomially distributed with p = 0.25.
   
   \item \textbf{STS Serial Test. Id(102)} - Accumulates the frequencies of overlapping n-tuples of bits drawn from a source of random integers.  The expected distribution of n-bit patterns is multinomial with p = $2^{(-n)}$ e.g. the four 2-bit patterns 00 01 10 11 should occur with equal probability. The target distribution is thus a simple chisq with $2^{n} - 1$ degrees of freedom, one lost due to the constraint that: p\_00 + p\_01 + p\_01 + p\_11 = 1 With overlap, though the test statistic is more complex. For example, given a bit string such as 0110100111000110 without overlap, it becomes 01|10|10|01|11|00|01|10 and we count 1 00, 3 01s, 3 10s, and 1 11. WITH overlap we get all of these patterns as well as (with cyclic wrap): 0|11|01|00|11|10|00|11|0 and we count 4 00s, 4 01s, 4 10s, and 3 11s. There is considerable covariance in the bit frequencies and a simple chisq test no longer suffices. The STS test uses target statistics that are valid for overlapping samples but which require multiple orders to generate. It is much easier to write a test that doesn't use overlapping samples and directly checks to ensure that the distribution of bit ntuples is consistent with a multinomial distribution with uniform probability $p = 1/2^n$, e.g. 1/8 for n = 3 bit, 1/16 for n = 4 bit NON-overlapping samples, and the rgb\_bitdist is just such a test. This test doesn't require comparing different orders. An open research question is whether or not test sensitivity significantly depends on managing overlap testing software RNGs where it is presumed that generation is cheap and unlimited. This question pertains to related tests, such as overlapping permutations tests (where non-overlapping permutation tests are isomorphic to non-overlapping frequency tests, fairly obviously). This test does all the possible bitlevel tests from n=1 to n=24 bits (where n=1 is basically sts\_monobit, and n=2 IMO is redundant with sts\_runs).  However, if I understand things correctly it is not possible to fail a 2 bit test and pass a 24 bit test, as if 2 bits are biased so that (say) 00 occurs a bit too often, then 24 bit strings containing 00's MUST be imbalanced as well relative to ones that do not, so we really only need to check n=24 bit results to get all the rest for free, so to speak.
   
   \item \textbf{RGB Bit Distribution Test. Id(200)} - Accumulates the frequencies of all n-tuples of bits in a list of random integers and compares the distribution thus generated with the theoretical (binomial) histogram, forming chisq and the associated p-value.  In this test n-tuples are selected without WITHOUT overlap (e.g. 01|10|10|01|11|00|01|10) so the samples are independent.  Every other sample is offset modulus of the sample index and ntuple\_max. This test must be run with -n ntuple for ntuple > 0.  Note that if ntuple > 12, one should probably increase tsamples so that each of the $2^{ntuple}$ bins should end up with an average of around 30 occurrences. Note also that the memory requirements and CPU time requirements will get quite large by e.g. ntuple = 20 - use caution when sampling the distribution of very large ntuples. 
   
   \item \textbf{THE GENERALIZED MINIMUM DISTANCE TEST. Id(201)} - This is the generalized minimum distance test, based on the paper of M. Fischler in the doc directory and private communications.  This test utilizes correction terms that are essential in order for the test not to fail for large numbers of trials.  It replaces both diehard\_2dsphere.c and diehard\_3dsphere.c, and generalizes the test itself so that it can be run for any d = 2,3,4,5.  There is no fundamental obstacle to running it for d = 1 or $d\>5$, but one would need to compute the expected overlap integrals (q) for the overlapping d-spheres in the higher dimensions.  Note that in this test there is no real need to stick to the parameters of Marsaglia.  The test by its nature has three controls: n (the number of points used to sample the minimum distance) which determines the granularity of the test - the approximate length scale probed for an excess of density; p, the usual number of trials; and d the dimension.  As Fischler points out, to actually resolve problems with a generator that had areas $20\%$ off the expected density (consistently) in $d = 2, n = 8000$ (Marsaglia's parameters) would require around 2500 trials, where p = 100 (the old test default) would resolve only consistent deviations of around 1.5 times the expected density.  By making both of these user selectable parameters, dieharder should be able to test a generator pretty much as thoroughly as one likes subject to the generous constraints associated with the eventual need for still higher order corrections as n and p are made large enough.
   
   \item \textbf{RGB Permutations Test. Id(202)} -  This is a non-overlapping test that simply counts order permutations of random numbers, pulled out n at a time.  There are n! permutations and all are equally likely.  The samples are independent, so one can do a simple chisq test on the count vector with n! - 1 degrees of freedom.  This is a poor-man's version of the overlapping permutations tests, which are much more difficult because of the covariance of the overlapping samples.
   
   \item \textbf{RGB Lagged Sums Test. Id(203)} - This package contains many very lovely tests.  Very few of them, however, test for lagged correlations -- the possibility that the random number generator has a bitlevel correlation after some fixed number of intervening bits. The lagged sums test is therefore very simple.   One simply adds up uniform deviates sampled from the rng, skipping lag samples in between each rand used.  The mean of tsamples samples thus summed should be 0,5*tsamples.  The standard deviation should be sqrt(tsamples/12). The experimental values of the sum are thus converted into a p-value (using the erf()) and a ks-test applied to psamples of them.
   
   \item \textbf{The Kolmogorov-Smirnov Test Test. Id(204)} - This test generates a vector of tsamples uniform deviates from the selected rng, then applies an Anderson-Darling or Kuiper KS test to it to directly test for uniformity.  The AD version has been symmetrized to correct for weak left bias for small sample sets; Kuiper is already ring-symmetric on the interval.  The AD code corresponds roughly to what is in R (thanks to a correction sent in by David Bauer). As always, the test is run pvalues times and the (same) KS test is then used to generate a final test pvalue, but the real purpose of this test is to test ADKS and KKS, not to test rngs.  This test clearly reveals that kstests run on only 100 test values (tsamples, herein) are only approximately accurate; their pvalues are distinctly high-biased (but less so than Kuiper or KS before the fix).  This bias is hardly visible for less than 1000 trivals (psamples, herein) but will constently cause failure for -t 100, -p 10000 or higher.  For -t 1000, it is much more difficult to detect, and the final kstest is approximately valid for the test in question.
   
   \item \textbf{DAB Byte Distribution Test. Id(205)} - Extract n independent bytes from each of k consecutive words. Increment indexed counters in each of n tables.  (Total of 256 $\times$ n counters.) Currently, n=3 and is fixed at compile time. If n>=2, then the lowest and highest bytes will be used, along with n-2 bytes from the middle. If the generator's word size is too small, overlapped bytes will be used. Current, k=3 and is fixed at compile time. Use a basic chisq fitting test (chisq\_pearson) for the p-value. Previous version also used a chisq independence test (chisq2d); it was found to be slightly less sensitive. I envisioned this test as using a small number of samples and large number of separate tests. Experiments so far show that keeping -p 1 and increasing -t performs best.
   
   \item \textbf{DCT (Frequency Analysis) Test. Id(206)} - This test performs a Discrete Cosine Transform (DCT) on the output of the RNG. More specifically, it performs tsamples transforms, each over an independent block of ntuple words. If tsamples is large enough, the positions of the maximum (absolute) value in each transform are recorded and subjected to a chisq test for uniformity/independence. [1] (A standard type II DCT is used.)  If tsamples is smaller than or equal to 5 times ntuple then a fallback test will be used, whereby all DCT values are converted to p-values and tested for uniformity via a KS test. This version is significantly less sensitive, and is not recommended. Power: With the right parameters, this test catches more GSL generators than any other; however, that count is biased by each of the randomNNN generators having three copies. Limitations: ntuple is required to be a power of 2, because a radix 2 algorithm is used to calculate the DCT. False positives: targets are (mostly) calculated exactly, however it will still return false positives when ntuple is small and tsamples is very large. For the default ntuple value of 256, I get bad scores with about 100 million or more tsamples (psamples set to 1). [1] The samples are taken as unsigned integers, and the DC coefficient is adjusted to compensate for this.
   
   \item \textbf{DAB Fill Tree Test. Id(207)} - This test fills small binary trees of fixed depth with words from the the RNG.  When a word cannot be inserted into the tree, the current count of words in the tree is recorded, along with the position at which the word would have been inserted. The words from the RNG are rotated (in long cycles) to better detect RNGs that may bias only the high, middle, or low bytes. The test returns two p-values.  The first is a Pearson chi-sq test against the expected values (which were estimated empirically).  The second is a Pearson chi-sq test for a uniform distribution of the positions at which the insert failed. Because of the target data for the first p-value, ntuple must be kept at the default (32).
   
   \item \textbf{DAB Fill Tree 2 Test. Id(208)} - Bit version of Fill Tree test. This test fills small binary trees of fixed depth with "visited" markers.  When a marker cannot be placed, the current count of markers in the tree and the position that the marker would have been inserted, if it hadn't already been marked. For each bit in the RNG input, the test takes a step right (for a zero) or left (for a one) in the tree. If the node hasn't been marked, it is marked, and the path restarts.  Otherwise, the test continues with the next bit. The test returns two p-values.  The first is a Pearson chi-sq test against the expected values (which were estimated empirically.  The second is a Pearson chi-sq test for a uniform distribution of the positions at which the insert failed. Because of the target data for the first p-value, ntuple must be kept at the default (128).
   
   \item \textbf{DAB Monobit 2 Test. Id(209)} - Block-monobit test. Since we don't know what block size to use, try multiple block sizes. In particular, try all block sizes of $2^k$ words, where k={0 \dots n}.  The value of n is calculated from the word size of the generator and the sample size used, and is shown as ntuple.
 \end{itemize} 

\section{Verificação das propriedades com ferramentas da teoria da informação} 
\subsection{aaa}
\begin{center}
	\fbox{
	\colorbox[RGB]{227, 227, 227}{
	\parbox[t]{.8\linewidth}
		{Neste capítulo tratamos da Revisão Bibliográfica realizada para o desenvolvimento do trabalho, no capítulo seguinte tratamos da metodologia utilizada do desenvolvimento do mesmo.}} }
\end{center}

\fi