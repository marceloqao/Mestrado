\mychapter{Delimitação do Problema}{chp:Fundamentação Teórica}
\lhead{Delimitação do Problema}

% Breve resumo do capítulo.
  \lettrine{E}{ste} capítulo tem como objetivo apresentar uma fundamentação teórica necessária para embasar os conceitos aplicados no trabalho.
Delimitaremos aqui o problema a ser tratado nesta tese.

Em relação a fundamentação teórica, utilizou-se como principal fonte de pesquisa a área de indexação de periódicos científicos ISI \emph{Web of Knowledge}, onde foram obtidas a grande maioria das referências, usando como parâmetros o fator de impacto dos periódicos pesquisados, a quantidade de citações de cada publicação, o grau de relevância para o tema pesquisado e o nível de produtividade (fator-H) dos autores envolvidos. O apoio em livros, surveys, lecture notes e ferramentas complementares de busca, como o \emph{google acadêmico} foram utilizadas para complementar esta pesquisa.

\section{Números Aleatórios} %Simulação física, Von Neumann, Congruenciais Lineares, etc
A noção de aleatoriedade é fundamental em diversas áreas, entretanto uma definição precisa, até mesmo do ponto de vista matemático rigoroso, é bastante difícil. Algumas questões emergem naturalmente como, o que vem a ser aleatoriedade? Existem eventos aleatórios na natureza? Faz algum sentido buscar leis da aleatoriedade? É possível simular a aleatoriedade? Estas são questões são muito difíceis, envolvendo, inclusive, os primórdios da investigação filosófica como discute \citep{Volchan:02}
Números aleatórios perfazem uma das partes mais importantes em aplicações computacionais nos vários campos do conhecimento, como aborda  \citep{Knuth:98}:
\begin{itemize}
     \item \textit{Simulação} - Quando um computador é usado para simular fenômenos naturais, números aleatórios são necessários para fazer as coisas de forma realística. Simulação abrange diversas áreas, desde o estudo de física nuclear (onde particulas são submetidas a colisões aleatórias) até pesquisa operacional (como, por exemplo, a taxa de pessoas que entram num aeroporto em intervalos aleatórios).
     \item \textit{Amostragem} - É praticamente impossível examinar todos os possíveis casos, porém uma amostra aleatória provê um palpite sobre como é o comportamento típico do fenômeno em questão.
     \item \textit{Análise Numérica} - Técnicas elaboradas para a solução de complexos problemas numéricos foram desenvolvidas utilizando-se números aleatórios.
     \item \textit{Programação de Computadores} - Valores aleatórios são uma ótima fonte de dados para testar a eficácia de algoritimos computacionais.
     \item \textit{Tomada de Decisão} - Existem relatos de que diversos executivos tomam suas decisões lançando moedas ou atirando dardos. Também há rumores de que professores universitários lançam suas notas de forma similar. Em alguns momentos é importante tomar decisões de forma não influenciada por qualquer agente externo.
     \item \textit{Criptografia} - Uma fonte de bits não viesada é essencial para diversos tipos de comunicações seguras, quando os dados precisam ser mantidos em sigilo.
     \item \textit{Estética} - Um pouco de aleatoriedade faz com que gráficos e músicas geradas por computador aparentem ser menos artificiais.
     \item \textit{Diversão} - Rolar dados, embaralhar cartas, girar rodas de roletas, etc., são passatempos facinantes para muitos. Estes usos tradicionais de números aleatórios sugeriram o nome ``Método de Monte Carlo''.
    \end{itemize}
Existem dois tipos básicos de geradores utilizados para produzir sequências aleatórias: GNAs $-$ Geradores de Números Aleatórios, do inglês (RNGs $-$ Random Number Generators) e GNPA $-$ Geradores de Números Pseudo Aleatórios, do inglês (PRNGs $-$ Pseudo Random Number Generators).
  \subsection{Geradores de Números Aleatórios - GNA}
  Geradores de Números Aleatórios utilizam uma fonte não determinística juntamente com algumas funções de processamento para produzir aleatoriedade. As Saídas deste tipo de gerador podem ser usadas diretamente como números aleatórios, desde que satisfaçam critérios rígidos de aleatoriedade, ou ainda servir como parâmetro de entrada para geradores de números pseudoaleatórios, vistos com mais detalhes na sequência. A maior parte dos geradores utiliza-se de fenômenos físicos naturais como, decaimento radioativo, ruidos termais em semiconcutores, amostras de som num local ruidoso, ruido no espectro eletromagnético, dentre outros que, por óbvia dedução, carecem de algum hardware específico para serem capturados. Na literatura é possível encontrar trabalhos relatando detalhadamente a criação de geradores de números aleatórios utilizando fontes de aleatoriedade apropriadas, em \citep{Fairfield:85} o autor descreve a geração de um fluxo de bits aleatórios baseado na instabilidade da frequência de um oscilador, evidentemente a construção de um gerador como o descrito anteriormente demanda o emprego de técnicas apuradas e um grande conhecimento teórico, além de necessitar, em sua grande maioria, de hardware especializado, o que gera uma barreira para os usuários que demandam tais dados aleatórios, desta sorte os usuários precisam se valer de técnicas alternativas para obter aleatoriedade.
  \subsection{Geradores de Números Pseudo Aleatórios - GNPA}
  Dadas as dificuldades descritas anteriormente, atualmente a maneira mais conveniente e confiável de se gerar números aleatórios para diversas aplicações é através de algoritmos com um sólido embasamento matemático. Tais algoritmos produzem uma sequência de números sabidamente não aleatórios ao todo, mas que aparentam comportar-se como números aleatórios independentes, isto é, tomada uma sequência de variáveis aleatórias Independentes e Identicamente Distribuídas sobre o Intervalo $(0,1)$ - $IID U(0,1)$. Tal sequência pode ser chamada de ``Pseudo Aleatória'' e o programa utilizado em sua produção de ``Gerador de Números Pseudo Aleatórios'' como define \citep{LEcuyer:98}

\section{Principais Testes Clássicos} %Revisão Cronológica/Conceitual

Existem duas abordagens para testar-se a capacidade de um GNPA gerar sequências ditas aleatórias, segundo \citep{LEcuyer:92} são elencados em teóricos e empíricos, os testes teóricos são bastante específicos para cada tipo de gerador, pois analisam o comportamento das sequências, já os testes empíricos valem-se de técnicas estatísticas objetivando avaliar o quão boas são as sequências produzidas por um determinado gerador, neste trabalho propomos um teste não paramétrico baseado em ferramentas da teoria da informação, na seção a seguir daremos uma breve introdução cronológica aos testes disponíveis na literatura e ao estado da arte.
  
 \subsection{Diehard}
 
 \subsection{NIST}
  Fundado em 1991, o NIST (Instituto Nacional de Padrões e Tecnologia) é uma agência não regulatória do Departamento de Comércio dos Estados Unidos da América (EUA) que tem por missão promover a inovação e a competitividade nos EUA através da ciência de medidas, padrões e tecnologia de forma a alavancar a segurança econômica e melhorar a qualidade de vida do povo americano.
  A Divisão de Segurança de Computadores (CSD) e o Centro de Pesquisa em Segurança Computacional (CSRC) facilitam a ampla disseminação de práticas e ferramentas de segurança da informação, provendo recursos para a definição de padrões além de identificar recursos de segurança na web para suportar usuários na industria, governo e academia. CSRC é o portal de acesso primário para se ter acesso às publicações de segurança de computadores, padrões e instruções, além de outras informações relacionadas a segurança.
  Desde 1997, o Grupo de Trabalho Técnico em Geração de Números Aleatórios (RNG-TWG) tem trabalhado no desenvolvimento de uma bateria de testes estatísticos apropriados para a avaliação de geradores de números aleatórios e pseudoaleatórios utilizados em aplicações criptográficas. 
  Os principais objetivos do grupo são:
  \begin{itemize}
   \item Desenvolvimento de uma bateria de testes estatísticos para detectar não aleatoriedade em sequencias binárias construidas através de geradores de números aleatórios e pseudoaleatórios utilizados em aplicações criptográficas;
   \item Produzir documentação e uma implementação em software destes testes;
   \item Prover auxílio no uso e aplicação destes testes.
  \end{itemize}
  Um total de quinze testes estatísticos foram desenvolvidos, implementados e avaliados. A seguir fazemos um breve descritivo acerca dos testes.

%  \begin{itemize}
%   \item \textbf{Frequency (Monobits) Test} - O foco do teste está na proporção de $zeros$ e $uns$ em toda a sequência. O propósito deste teste é determinar em que momento o número de $zeros$ e $uns$ numa sequência é aproximadamente o mesmo como é o esperado para uma sequência realmente aleatória. O teste avalia a proximidade da porção de $uns$ a $½$, ou seja, o número de $zeros$ e $uns$ numa sequência deve ser o mesmo.
%%    The focus of the test is the proportion of zeroes and ones for the entire sequence. The purpose of this test is to determine whether that number of ones and zeros in a sequence are approximately the same as would be expected for a truly random sequence. The test assesses the closeness of the fraction of ones to ½, that is, the number of ones and zeroes in a sequence should be about the same.
%   \item \textbf{Test For Frequency Within A Block} - O teste avalia a proporção de $zeros$ e $uns$ em blocos de M bits. O propósito principal deste teste é determinar se a frequência de $uns$ em um bloco de $M$ bits é aproximadamente $M/2$.
%%    The focus of the test is the proportion of zeroes and ones within M-bit blocks. The purpose of this test is to determine whether the frequency of ones is an M-bit block is approximately M/2.
%   \item \textbf{Runs Test} -  Dada uma sequência ininterrupta de zeros ou de $uns$, chamaremos esta sequência de ``rodada'' e de ``k'' tamanho da sequência. O objetivo do teste é determinar a proporção de rodadas de zeros e $uns$ de diversos tamanhos ``k'' necessária para caracterizar uma sequência com aleatória. Em particular, este teste determina quando a oscilação enter estas substrings é muito rápida ou muito lenta.
%%    The focus of this test is the total number of zero and one runs in the entire sequence, where a run is an uninterrupted sequence of identical bits. A run of length k means that a run consists of exactly k identical bits and is bounded before and after with a bit of the opposite value. The purpose of the runs test is to determine whether the number of runs of ones and zeros of various lengths is as expected for a random sequence. In particular, this test determines whether the oscillation between such substrings is too fast or too slow.
%   \item \textbf{Test For The Longest Run Of Ones In A Block} - O teste tem como objetivo determinar quando o comprimento da maior rodada de $uns$ na sequência testada é equivalente ao tamanho da maior rodada esperada em uma sequência aleatória. Note que uma irregularidade no tamanho esperado no valor da maior rodada de $uns$ implica que também há uma irregularidade no tamanho esperado da rodada de $zeros$ mais longa.
%%    The focus of the test is the longest run of ones within M-bit blocks. The purpose of this test is to determine whether the length of the longest run of ones within the tested sequence is consistent with the length of the longest run of ones that would be expected in a random sequence. Note that an irregularity in the expected length of the longest run of ones implies that there is also an irregularity in the expected length of the longest run of zeroes. Long runs of zeroes were not evaluated separately due to a concern about statistical independence among the tests.
%   \item \textbf{Random Binary Matrix Rank Test} - O teste avalia a categoria das submatrizes disjuntas da sequência toda. O objetivo do teste é verificar a ocorrência de dependência linear entre substrings de tamanho fixo da sequência original.
%%    The focus of the test is the rank of disjoint sub-matrices of the entire sequence. The purpose of this test is to check for linear dependence among fixed length substrings of the original sequence.
%   \item \textbf{Discrete Fourier Transform (Spectral) Test} - O teste foca nos picos da \texttt{Transformada Rápida de Fourrier} com o propósito de detectar característica periódicas.
%%    The focus of this test is the peak heights in the discrete Fast Fourier Transform. The purpose of this test is to detect periodic features (i.e., repetitive patterns that are near each other) in the tested sequence that would indicate a deviation from the assumption of randomness.
%   \item \textbf{Non-Overlapping (Aperiodic) Template Matching Test} - O teste observa o número de ocorrências de substrings predefinidas com o propósito de rejeitar sequências que possuam muitas ocorrências de um dado padrão aperiódico. Para tal uma janela de $m$ bits é usada para procurar por um padrão específico de "m" bits.
%%    The focus of this test is the number of occurrences of pre-defined target substrings. The purpose of this test is to reject sequences that exhibit too many occurrences of a given non-periodic (aperiodic) pattern. For this test and for the Overlapping Template Matching test, an m-bit window is used to search for a specific m-bit pattern. If the pattern is not found, the window slides one bit position. For this test, when the pattern is found, the window is reset to the bit after the found pattern, and the search resumes.
%   \item \textbf{Overlapping (Periodic) Template Matching Test} - O teste, assim com o o anterior, procura por substrings predefinidas de rodadas de $uns$ com um dado tamanho. O objetivo do teste é rejeitar sequências que mostrem um desvio do número esperado de $uns$ de um dado tamanho. Note que, quando há um desvio no número de $uns$, este desvio também ocorre com o número de $zeros$. Da mesma forma que o teste anterior, uma janela de $m$ bits é usada para detectar a presença de padrões.
%%    The focus of this test is the number of pre-defined target substrings. The purpose of this test is to reject sequences that show deviations from the expected number of runs of ones of a given length. Note that when there is a deviation from the expected number of ones of a given length, there is also a deviation in the runs of zeroes. Runs of zeroes were not evaluated separately due to a concern about statistical independence among the tests. For this test and for the Non-overlapping Template Matching test, an m-bit window is used to search for a specific m-bit pattern. If the pattern is not found, the window slides one bit position. For this test, when the pattern is found, the window again slides one bit, and the search is resumed.
%   \item \textbf{Maurer's Universal Statistical Test} - O teste observa o número de bits entre padrões casados com o objetivo de detectar ou não se a sequência pode ser significativamente comprimida sem a perda de informação. Uma sequência que pode ser totalmente comprimida é considerada como não aleatória.
%%    The focus of this test is the number of bits between matching patterns. The purpose of the test is to detect whether or not the sequence can be significantly compressed without loss of information. An overly compressible sequence is considered to be non-random.
%   \item \textbf{Linear Complexity Test} - O teste focaliza no tamanho de um registro gerador de informação com o objetivo de determinar quando ou não a sequência é complexa o suficiente para ser considerada aleatória. Sequências aleatórias são caracterizadas por um registro gerador de informação longo.
%%    The focus of this test is the length of a generating feedback register. The purpose of this test is to determine whether or not the sequence is complex enough to be considered random. Random sequences are characterized by a longer feedback register. A short feedback register implies non-randomness.
%   \item \textbf{Serial Test} - O teste detem o foco sobre a frequência de cada bit e de todos os padrões sobrepostos de $m$ bits em toda a sequência, com o propósito de determinar quando o número de ocorrências de padrões sobrepostos de 2m $m$ bits é o mesmo do esperado para sequências aleatórias, sabendo que o padrão pode ser sobreposto.
%%    The focus of this test is the frequency of each and every overlapping m-bit pattern across the entire sequence. The purpose of this test is to determine whether the number of occurrences of the 2m m-bit overlapping patterns is approximately the same as would be expected for a random sequence. The pattern can overlap.
%   \item \textbf{Approximate Entropy Test} - O teste se detém na frequência de cada um dos padrões sobrepostos de $m$ bits com o objetivo de comparar a frequência de dois blocos sobrepostos de tamanhos consecutivos/adjacentes ($m$ e $m+1$) com os valores esperados para uma sequência aleatória.
%%    The focus of this test is the frequency of each and every overlapping m-bit pattern. The purpose of the test is to compare the frequency of overlapping blocks of two consecutive/adjacent lengths (m and m+1) against the expected result for a random sequence.
%   \item \textbf{Cumulative Sum (Cusum) Test} - O teste verifica a distância máxima do ``passeio aleatório'' definido pela soma dos dígitos ajustados ($-1$, $+1$) na sequência com o objetivo de determinar quando a soma cumulativa da sequência parcial que ocorre nas sequências testadas é muito grande ou muito pequeno em relação ao comportamento esperado para sequências aleatórias. Esta sequência cumulativa pode ser considerada como um ``passeio aleatório''. Para uma sequência aleatória, o ``passeio aleatório'' deve ser próximo a $zero$ e para sequências não aleatórias a excursão máxima do ``passeio aleatório'' se distancia de zero e tende a ser grande.
%%    The focus of this test is the maximal excursion (from zero) of the random walk defined by the cumulative sum of adjusted (-1, +1) digits in the sequence. The purpose of the test is to determine whether the cumulative sum of the partial sequences occurring in the tested sequence is too large or too small relative to the expected behavior of that cumulative sum for random sequences. This cumulative sum may be considered as a random walk. For a random sequence, the random walk should be near zero. For non-random sequences, the excursions of this random walk away from zero will be too large.
%   \item \textbf{Random Excursions Test} - O teste verifica o número de ciclos que possuem exatamente $K$ visitas em uma soma cumulativa do tipo ``passeio aleatório''. A soma cumulativa é encontrada se a soma parcial das sequências de ($0$, $1$) está ajustada a ($-1$, $+1$). Uma ``jornada aleatória'' de um ``passeio aleatório'' consiste em uma sequência de $n$ passos de tamanho unitário tomados aleatoriamente iniciando e terminando na origem. O objetivo deste teste é determinar se o número de visitas a um estado em um ``passeio aleatório'' excede o esperado para uma sequência aleatória.
%%    The focus of this test is the number of cycles having exactly K visits in a cumulative sum random walk. The cumulative sum random walk is found if partial sums of the (0,1) sequence are adjusted to (-1, +1). A random excursion of a random walk consists of a sequence of n steps of unit length taken at random that begin at and return to the origin. The purpose of this test is to determine if the number of visits to a state within a random walk exceeds what one would expect for a random sequence.
%   \item \textbf{Random Excursions Variant Test} - O teste verifica o número de vezes que um estado em particular ocorreu na soma cumulativa de um ``passeio aleatório'' com o objetivo de detectar desvios do número esperado de ocorrências de vários estados do ``passeio aleatório''.
%%    The focus of this test is the number of times that a particular state occurs in a cumulative sum random walk. The purpose of this test is to detect deviations from the expected number of occurrences of various states in the random walk.
%  \end{itemize}

  \subsection{Dieharder}
  A suíte de testes Diehard tem algumas limitações como, Robert RGB reescreveu-os numa linguagem portável como C e acrescentou ao conjunto de testes disponíveis no Diehard alguns outros testes do NIST e mais alguns de sua autoria, listados na tabela \ref{Tab:DieharderTests} e explicados abaixo.

%   \begin{itemize}
%   \item \textbf{``Birthdays'' test (modificado). Id(0)} -  Este teste baseia-se no Paradoxo do Aniversário Cada teste determina o número de intervalos que combinam 512 ``aniversários'' (por padrão) tomados num ``ano'' fictício de 24 bits (por padrão). Este processo é repetido (por padrão) 100 vezes e o resultado é acumulado em um histograma. Intervalos repetidos podem ser distribuidos em uma distribuição Poisson se o gerador em questão for aleatório o suficiente, e em uma Chi Quadrado com o p-valor avaliado relativamente à hipótese nula. É recomendado rodar este teste próximo ou com exatamente 100 amostras por p-valor com \texttt{-t 100}. Dois parametros adicionais foram incluidos. No Diehard, nms=512, porém isto pode ser variado e todas as fórmulas de Marsaglia continuam a funcionar. Pode ser ajustado para valores diferentes com \texttt{-x nmsvalue}. Similarmente, o parâmetro \texttt{nbits}pode ser 24, mas podemos fazê-lo assumir qualquer valor desde que seja menor ou igual a \texttt{rmax\_bits = 32}. E pode ser atribuido qualquer valor com o parâmetro \texttt{-y nbits}. Ambos são padrão para os valores do Diehard se as opções \texttt{-x e -y} não forem utilizadas.
%   
%   \item \textbf{Diehard Overlapping 5-Permutations Test. Id(1)} - O teste procura por uma sequência aleatória de $10^6$ inteiros. Cada conjunto de cinco inteiros consecutivos pode estar em um dos $120$ estados, para as $5!$ possíveis combinações de cinco números. Portanto, cada um dos $5^{o}$, $6^{o}$, $7^{o}$, \dots fornecem um estado. Assim, como milhares de transições de estado são observadas, contadores cumulativos são gerados a partir do número de ocorrências de cada estado. Logo, a forma quadrática na inveresa fraca da matriz de covariância $120\times120$ produz um teste equivalente ao do teste da taxa de verossimilhança, onde as 120 células vêem da distribuição normal (assintoticamente) especificada com a específica matriz de covariância $120\times120$ (com rank 99). Esta versão usa $1.000.000$ de inteiros, duas vezes. Note que o Dieharder executa o teste 100 vezes por padrão e não 2.
%%    This is the OPERM5 test.  It looks at a sequence of one million 32-bit random integers.  Each set of five consecutive integers can be in one of 120 states, for the 5! possible orderings of five numbers.  Thus the 5th, 6th, 7th, \dots numbers each provide a state. As many thousands of state transitions are observed,  cumulative counts are made of the number of occurences of each state.  Then the quadratic form in the weak inverse of the 120x120 covariance matrix yields a test equivalent to the likelihood ratio test that the 120 cell counts came from the specified (asymptotically) normal distribution with the specified 120x120 covariance matrix (with rank 99).  This version uses 1.000.000 integers, twice. Note that Dieharder runs the test 100 times, not twice, by default.
%   
%   \item \textbf{Diehard 32x32 Binary Rank Test. Id(2)} - Neste teste uma matriz binária $32\times32$ é formada com cada linha contendo um inteiro aleatório de 32 bits. O rank é determinado e pode assumir valores de $0$ a $32$, ranks menores de 29 são raros e suas ocorrências são acumuladas no rank 29. Os ranks são calculados para as $40.000$ matrizes e um teste chi quadrado é realizado nas contagens para os ranks $32, 31, 30 e \leqslant 29$. Como de costume na bateria de testes, o teste é repetido e um teste KS (Kolmogorov Smirnov) é aplicado aos $p-valores$ obtidos afim de verificar se eles são uniformes.
%%    This is the BINARY RANK TEST for $32\times32$ matrices. A random $32\times32$ binary matrix is formed, each row a 32\-bit random integer. The rank is determined. That rank can be from 0 to 32, ranks less than 29 are rare, and their counts are pooled with those for rank 29.  Ranks are found for $40.000$ such random matrices and a chisquare test is performed on counts for ranks $32, 31, 30 and \leqslant 29$. As always, the test is repeated and a KS test applied to the resulting p \textendash values to verify that they are approximately uniform.
%
%   \item \textbf{Diehard 6x8 Binary Rank Test. Id(3)} - Neste teste cada uma dos $seis$ inteiros aleatórios de $32$ bits do gerador submetido ao teste tem um $byte$ escolhido e os $seis$ bits resultantes formam uma matriz binária $6\times8$ cujo rank é determindado. Este rank pode ser de $0$ a $6$, porém ranks $0, 1, 2, 3$ são raros e seus valores são armazendados juntamente daqueles de rank $4$. São encontrados os ranks para $100.000$ matrizes aleatórias e um testes chi quadrado é aplicado aos contadores para os ranks $6, 5 e \leqslant4$. Como sempre, o teste é repetido e um teste KS é aplicado ao $p-valor$ resultante para verificar se eles são uniformmes.
%%    This is the BINARY RANK TEST for $6\times8$ matrices.  From each of six random 32\-bit integers from the generator under test, a specified byte is chosen, and the resulting six bytes form a $6\times8$ binary matrix whose rank is determined.  That rank can be from 0 to 6, but ranks $0, 1, 2, 3$ are rare; their counts are pooled with those for rank 4. Ranks are found for $100.000$ random matrices, and a chi-square test is performed on counts for ranks $6, 5 and \leqslant4$. As always, the test is repeated and a KS test applied to the resulting p \textendash values to verify that they are approximately uniform.
%   
%   \item \textbf{Diehard Bitstream Test. Id(4)} - O arquivo sob teste é visto como um fluxo de bits. Chamaremo-os $b_1$,$b_2$,$\dots$ . Considere um alfabeto de duas ``letras'', $0$ e $1$ e pense no fluxo de bits como uma sucessão de ``palavras'' de $20$ letras com sobreposição. Então, a primeira palavra é $b_1$ $b_2$ $\dots$ $b_{20}$, o segundo é $b_2$ $b_3$ $\dots$ $b_{21}$ e assim por diante. O teste conta o número de palavras de $20$ letras ou $20$ bits ausentes numa string de $2^{(21)}$ sobrepondo palavras de $21$ letras. Dado que existem $2^{20}$ possíveis palavras de $20$ letras, para uma string realmente aleatória de $2^{21}+19$ bits, o número de palavras ausentes ``j'' deve ser (ou bem próximo de) normalmente distribuido com média $141.909$ e $\sigma = 428$. Logo, $(j-141909)/428$ deve ser a variação (z score) que nos leva a um ($p-value$) uniforme $[0.1)$. O teste é repetido vinte vezes. Note que o teste é repetido 100 vezes por padrão no $dieharder$, mas o tamanho da amostra é fixo ($t-samples$ não devem/podem ser modificados do padrão), neste teste $\sigma$ requer o uso de amostras sobrepostas, e tais amostras não são independentes. Caso queira usar a versão sem sobreposição do teste, $\sigma = 290$ precisa ser utilizado.
%%    The file under test is viewed as a stream of bits. Call them  $b_1$,$b_2$,\dots  .  Consider an alphabet with two ``letters'', 0 and 1 and think of the stream of bits as a succession of 20-letter ``words'', overlapping.  Thus the first word is $b_1$ $b_2$\dots$b_{20}$, the second is $b_2$ $b_3$\dots$b_{21}$, and so on.  The bitstream test counts the number of missing 20\-letter (20\-bit) words in a string of 2(21) overlapping 20\-letter words.  There are $2^{20}$ possible 20 letter words.  For a truly random string of $2^{21}+19$ bits, the number of missing words j should be (very close to) normally distributed with mean $141.909$ and sigma 428. Thus (j-141909)/428 should be a standard normal variate (z score) that leads to a uniform [0,1) p\-value. The test is repeated twenty times.
%%    NOTE WELL!
%%    The test is repeated 100 times by default in dieharder, but the size of the sample is fixed (tsamples cannot/should not be varied from the  default).  The sigma of this test REQUIRES the use of overlapping samples, and overlapping samples are not independent. If one uses the non-overlapping version of this test, sigma = 290 is used instead, smaller because now there are $2^{21}$ INDEPENDENT samples.
%   
%   \item \textbf{Diehard Overlapping Pairs Sparse Occupance (OPSO). Id (5)} - O teste considera palavras de $2$ letras em um alfabeto de $1024$ letras, cada letra é determinada por $10$ bits específicos em uma sequência inteira de $32$ bits a ser testada. O mesmo gera $2^{21}$ palavras (sobrepostas) de $2$ bits (de um total de $2^{21}+1$ ``teclas pressionadas'' e conta o número de palavras ausentes, ou seja, palavras de $2$ letras que não aparecem em toda a sequência. Esta contagem precisa ser muito próxima de normalmente distribuida com média $141909$, $\sigma 290$. Logo $(ausentes-141909)/290$ deve ser a variação padrão normal. O teste toma 32 bits do arquivo a ser testado por vez e usa um conjunto específico de dez bits consecutivos. Então reinicia o arquivo para os próximos dez bits e assim por diante. Note que $2^{21}=2097152$, $tsamples$ não podem ser variados.
%%    The OPSO test considers 2\-letter words from an alphabet of 1024 letters.  Each letter is determined by a specified ten bits from a 32\-bit integer in the sequence to be tested. OPSO generates  $2^{21}$ (overlapping) 2\-letter words (from $2^{21}+1$ ``keystrokes'')  and counts the number of missing words that is 2\-letter words which do not appear in the entire sequence. That count should be very close to normally distributed with mean $141.909, \sigma290$. Thus $(missingwrds\-141909)\diagup290$ should be a standard normal variable. The OPSO test takes 32 bits at a time from the test file and uses a designated set of ten consecutive bits. It then restarts the file for the next designated 10 bits, and so on. Note $2^{21} = 2097152$, tsamples cannot be varied.
%   
%   \item \textbf{Diehard Overlapping Quadruples Sparce Occupancy (OQSO) Test. Id(6)} - Similarmente ao teste anterior, exceto pelo fato de considerar palavras de $4$ letras em um alfabeto de 32 letras, cada letra determinada por uma determinada string de $5$ bits consecutivos do arquivo testado. O número médio de palavras ausentes numa sequência de $2^{21}$ palavras de $4$ letras, ($2^{21}+3$ ``teclas pressionadas'') é novamente $141909$, com $\sigma=295$. A média é baseada na teoria, $\sigma$ vem de exaustiva simulação. Note que $2^{21}=2097152$, tsamples não podem ser variados.
%%    Similar, to OPSO except that it considers 4\-letter words from an alphabet of 32 letters, each letter determined by a designated string of 5 consecutive bits from the test file, elements of which are assumed 32\-bit random integers. The mean number of missing words in a sequence of $2^{21}$ four\-letter words, ( $2^{21}$ + 3 ``keystrokes'' ), is again $141909$, with $\sigma$ = 295. The mean is based on theory, $\sigma$ comes from extensive simulation. Note $2^{21} = 2097152$, tsamples cannot be varied.
%   
%   \item \textbf{Diehard DNA Test. Id(7)} - O teste considera um alfabeto de $4$ letras \texttt{C,G,A,T}, determinadas por dois bits significativos na sequência de inteiros aleatórios que está sendo testada. Avaliando palavras de $10$ letras, assim como no OPSO e OQSO, existem $2^{20}$ possíveis palavras, e o número médio de palavras faltantes em uma sequência de $2^{21}$ sobrepondo palavras de $10$ letras ($2^{21}+9$ ``teclas pressionadas'') é 141909. O desvio padrão $\sigma=339$ foi determinado assim como para OQSO, por simulação.
%%    The DNA test considers an alphabet of 4 letters: \texttt{C,G,A,T}, determined by two designated bits in the sequence of random integers being tested. It considers 10\-letter words, so that as in OPSO and OQSO, there are $2^{20}$ possible words, and the mean number of missing words from a string of $2^{21}$ (over-lapping)  10\-letter words ($2^{21}+9$ ``keystrokes'') is 141909. The standard deviation $\sigma$=339 was determined as for OQSO by simulation. ($\sigma$ for OPSO, $290$, is the true value (to three places), not determined by simulation. Note $2^{21} = 2097152$. Note also that we don't bother with overlapping keystrokes (and sample more rands \- rands are now cheap). 
%
%   \item \textbf{Diehard Count the 1s (stream) (modified) Test. Id(8)} - Neste teste o arquivo avaliado é tratado como um fluxo de bytes (quatro para cada inteiro de 32 bits). Cada byte pode conter de $0 a 8$ uns, Com probabilidades $1, 8, 28, 56, 70, 56, 28, 8, 1 sobre  256$. Desta forma, deixemos que o fluxo de bytes forneça uma string de $5$ palavras com sobreposição, onde cada ``letra'' assume os valores $A, B, C, D, E$. As letras são determinadas pela quantidades de ``uns'' em um byte: 0, 1 ou 2 representam A, 3 representa B, 4 representa C, 5 representa D e 6, 7 ou 8 representam E. Desta forma, temos 5 teclas sendo pressionadas com diversas probabilidades ($37,56,70,56,37 sobre 256$). Existem $5^{5}$ palavras de $5$ letras, e para uma sequência de palavras de $5$ letras de tamanho $256.000$ com sobreposição, a contagem é realizada a partir da frequência com a qual cada palavra ocorre. A forma quadrática da contagem de células na matriz de covarância inversa fraca provê um teste chi quadrado: $Q5-Q4$ a diferença das somas de Pearson de $(OBS-EXP)^2/EXP$ nas contagens para células de 5 letras e 4 letras.
%%    Consider the file under test as a stream of bytes (four per 32 bit integer).  Each byte can contain from 0 to 8 1's, with probabilities 1,8,28,56,70,56,28,8,1 over 256.  Now let the stream of bytes provide a string of overlapping  5-letter words, each ``letter'' taking values A,B,C,D,E. The letters are determined by the number of 1's in a byte:  0, 1, or 2 yield A, 3 yields B, 4 yields C, 5 yields D and 6, 7 or 8 yield E. Thus we have a monkey at a typewriter hitting five keys with various probabilities (37,56,70,56,37 over 256).  There are $5^{5}$ possible 5\-letter words, and from a string of 256.000 (over-lapping) 5\-letter words, counts are made on the frequencies for each word. The quadratic form in the weak inverse of the covariance matrix of the cell counts provides a chisquare test: Q5-Q4, the difference of the naive Pearson sums of $(OBS-EXP)^2/EXP$ on counts for 5 and 4-letter cell counts.
%   
%   \item \textbf{Diehard Count the 1s Test (byte) (modified). Id(9)} - Este é o teste ``Conte os uns'' para bytes específicos. Considera o arquivo testado como um fluxo de inteiros de 32 bits. Para cada inteiro, um byte específico é escolhido, digamos que os bits de $1 a 8$ à esquerda. Como cada byte pode conter de $0 a 8$ uns, com probabilidades $1, 8, 28, 56, 70, 56, 28, 8, 1 sobre 256$. Então tomemos os bytes específicos dos sucessivos inteiros proverem uma sequência de palavras de $5$ letras com sobreposição, onde cada letra podendo assumir os valores $A, B, C, D, E$. Sendo as letras determinadas pela quantidade de uns em um dado byte desta forma: $0, 1, ou 2 \rightarrow A, 3 \rightarrow B, 4 \rightarrow C, 5 \rightarrow D,  and 6, 7 ou 8 \rightarrow E$. Desta forma, temos 5 teclas sendo pressionadas com diversas probabilidades ($37,56,70,56,37 sobre 256$). Existem $5^{5}$ palavras de $5$ letras, e para uma sequência de palavras de $5$ letras de tamanho $256.000$ com sobreposição, a contagem é realizada a partir da frequência com a qual cada palavra ocorre. A forma quadrática da contagem de células na matriz de covarância inversa fraca provê um teste chi quadrado: $Q5-Q4$ a diferença das somas de Pearson de $(OBS-EXP)^2/EXP$ nas contagens para células de 5 letras e 4 letras. Nota: O teste é executado em rodadas sobre amostras em todo o espaço de $0-31$ bits, logo, se há algum problema com alguma sequência em particular, há chance deste problema ser detectado. Pode-se imaginar problemas com sequências ímpares e não com sequências pares. O parâmetro ``tsamples'' e ``psamples'' podem ser livremente variados, porém é sensato manter ``tsamples'' $\gg 100.000$ para obter-se um resultado confiável num teste KS.
%%    This is the COUNT\-THE\-1's TEST for specific bytes. Consider the file under test as a stream of 32\-bit integers. From each integer, a specific byte is chosen, say the left\-most: bits 1 to 8. Each byte can contain from 0 to 8 1's, with probabilitie 1, 8, 28, 56, 70, 56, 28, 8, 1 over 256.  Now let the specified bytes from successive integers provide a string of (overlapping) 5\-letter words, each ``letter'' taking values A,B,C,D,E. The letters are determined  by the number of $1's$, in that byte: $0,  1,  or  2 \rightarrow A,  3 \rightarrow B,  4 \rightarrow C,  5 \rightarrow D,  and  6,  7 or  8 \rightarrow E$. Thus we have a monkey at a typewriter hitting five keys with with various probabilities: 37, 56, 70, 56, 37 over 256. There are $5^5$ possible 5\-letter words, and from a string of 256.000 (overlapping) 5\-letter words, counts are made on the frequencies for each word. The quadratic form in the weak inverse of the covariance matrix of the cell counts provides a chisquare test: Q5\-Q4, the difference of the naive Pearson sums of $(OBS-EXP)^2/EXP$ on counts for 5 and 4-letter cell counts. Note: We actually cycle samples over all 0\-31 bit offsets, so that if there is a problem with any particular offset it has a chance of being observed.  One can imagine problems with odd offsets but not even, for example, or only with the offset 7. tsamples and psamples can be freely varied, but you'll likely need $tsamples \gg 100.000$ to have enough to get a reliable kstest result. 
%
%   \item \textbf{Diehard Parking Lot Test (modified). Id(10)} - Este teste verifica a distribuição das tentativas de estacionar um ``carro quadrado'' de tamanho 1 em um estacionamento que mede $100\times100$ sem causar nenhum acidente. O resultado é plotado em $n \times k$ onde $n$ é o número de tentativas e $k$ o números de tentativas que foram bem sucedidas, ou seja, não houve um acidente de se colocar um carro onde já havia um (sobreposição), comparado com o resultado esperado de um conjunto perfeitamente randômico de coordenadas de vagas. Isto não é realmente conhecido no campo teórico, então ao invés de comparar com $n=12.000$ onde k deve ter média $3523$ com $\sigma=21.9$ e é muito próxima da normal. Então, $(k-3523)/21.9$ é uma variável normal padrão, a qual convertida a um $p-valor$ uniforme, provê valores para um teste KS com $100$ amostras padrão.
%%    This tests the distribution of attempts to randomly park a square car of length 1 on a 100x100 parking lot without crashing.  We plot n (number of attempts) versus k (number of attempts that didn't "crash" because the car squares  overlapped and compare to the expected result from a perfectly random set of parking coordinates.  This is, alas, not really known on theoretical grounds so instead we compare to n=12,000 where k should average 3523 with sigma 21.9 and is very close to normally distributed. Thus (k-3523)/21.9 is a standard normal variable, which converted to a uniform p-value, provides input to a KS test with a default 100 samples.
%   
%   \item \textbf{Diehard Minimum Distance (2d Circle) Test Id(11)} - O teste repete $100$ vezes: escolhe $n=8.000$ pontos aleatórios em um quadrado de lados $10.000$. Encontra $d$, a distância mínima entre os $(n^2-n)/2$ pares de pontos. Se os pontos são realmente independentes e uniformes, então $d^2$, o quadrado da distância mínima deve ser distribuido exponencialmente (ou muito próximo disto) com média $0.995$. Então $1-exp(-d^2/0.995)$ deve ser uniforme em $[0,1)$ e um teste KS nos 100 valores resultantes serve como um teste de uniformidade para pontos aleatórios no quadrado. $numbers=0 mod 5$ são apresentados, porém o teste KS é baseado no conjunto completo de 100 escolhas dentre os $8.000$ pontos no  quadrado de $10.000 \times 10.000$. Este teste usa um número fixo de amostras (tsamples é ignorado). Ele também usa o valor padrão de 100 psamples no teste KS final.
%%    It does this 100 times: choose $n=8.000$ random points in a square of side 10.000. Find d, the minimum distance between the $(n^2-n)/2$ pairs of points.  If the points are truly independent uniform, then $d^2$, the square of the minimum distance should be (very close to) exponentially distributed with mean $0.995$.  Thus $1-exp(-d^2/0.995)$ should be uniform on $[0,1)$ and a KSTEST on the resulting 100 values serves as a test of uniformity for random points in the square. Test $numbers=0 mod 5$  are printed but the KSTEST is based on the full set of 100 random choices of 8.000 points in the $10.000x10.000$ square. This test uses a fixed number of samples \- tsamples is ignored. It also uses the default value of 100 psamples in the final KS test, for once agreeing precisely with Diehard.
%   
%   \item \textbf{Diehard 3d Sphere (Minimum Distance) Test. Id(12)} - Neste teste são escolhidos $4.000$ pontos em um cubo de aresta $1.000$. Em cada ponto, centralize uma esfera grande o suficiente para alcançar o ponto mais próximo. Então, o volume da menor esfera é exponencialmete distribuido com média $120\pi/3$. E o raio ao cubo é exponencial com média 30. (A média é obtida através de exaustivas simulações). O teste gera $4.000$ esferas repetidas por $20$ vezes. Cada raio mínimo inscrito no cubo leva-nos a uma variável aleatória uniforme com média $1-exp(-r^3/30)$, então é realizado um teste KS nos $20$ p-valores. Este teste ignora ``tsamples'' e roda o padrão de $100$ psamples para usar no teste KS final. 
%%    Choose  4.000 random points in a cube of edge 1.000.  At each point, center a sphere large enough to reach the next closest point. Then the volume of the smallest such sphere is (very close to) exponentially distributed with mean $120\pi/3$. Thus the radius cubed is exponential with mean 30. (The mean is obtained by extensive simulation). The 3DSPHERES test generates 4.000 such spheres 20 times. Each min radius cubed leads to a uniform variable by means of $1-exp(-r^3/30)$, then a KSTEST is done on the 20 p-values. This test ignores tsamples, and runs the usual default 100 psamples to use in the final KS test.
%   
%   \item \textbf{Diehard Squeeze Test. Id(13)} - 
%Random integers are floated to get uniforms on [0,1). Starting with $k=2^{31}$=2147483647, the test finds j, the number of iterations necessary to reduce k to 1, using the reduction $k = ceiling(k \times U)$, with U provided by floating integers from the file being tested. Such j's are found 100.000 times, then counts for the number of times j was $\leq 6, 7,\dots, 47, \geq 48$ are used to provide a chi\-square test for cell frequencies. 
%   
%   \item \textbf{Diehard Sums Test Id(14)} - Integers are floated to get a sequence $U(1),U(2),\dots$ of uniform [0,1) variables. Then overlapping sums, $S(1) = U(1)+ \dots + U(100), S2 = U(2)+ \dots +U(101), \dots$ are formed. The S's are virtually normal with a certain covariance matrix.  A linear transformation of the S's converts them to a sequence of independent standard normals, which are converted  to uniform variables for a KSTEST. The p\-values from ten KSTESTs are given still another KSTEST. Comments At this point I think there is rock solid evidence that this test is completely useless in every sense of the word. It is broken, and it is so broken that there is no point in trying to fix it. The problem is that the transformation above is not linear, and doesn't work. Don't use it. For what it is worth, rgb\_lagged\_sums with ntuple 0 tests for exactly the same thing, but scalably and reliably without the complication of overlapping samples and covariance. Use it instead.
%   
%   \item \textbf{Diehard Runs Test. Id(15)} - This is the RUNS test. It counts runs up, and runs down, in a sequence of uniform [0,1) variables, obtained by floating the 32-bit integers in the specified file. This example    shows how runs are counted:  .123,.357,.789,.425,.224,.416,.95 contains an up-run of length 3, a down-run of length 2 and an  up-run of (at least) 2, depending on the next values.  The     covariance matrices for the runs-up and runs-down are well     known, leading to chisquare tests for quadratic forms in the   weak inverses of the covariance matrices.  Runs are counted    for sequences of length 10.000.  This is done ten times. Then  repeated. In Dieharder sequences of length tsamples = 100000 are used by default, and 100 p-values thus generated are used in a final KS test.
%   
%   \item \textbf{Diehard Craps Test. Id(16)} - This is the CRAPS TEST. It plays 200.000 games of craps, finds  the number of wins and the number of throws necessary to end  each game.  The number of wins should be (very close to) a normal with mean 200000p and variance 200000p(1-p), with p=244/495.  Throws necessary to complete the game can vary from 1 to infinity, but counts for all > 21 are lumped with 21. A chi-square test is made on the number-of-throws cell counts. Each 32-bit integer from the test file provides the value for the throw of a die, by floating to [0,1), multiplying by 6 and taking 1 plus the integer part of the result.
%   
%   \item \textbf{Marsaglia and Tsang GCD Test. Id(17)} - $10^7$ tsamples (default) of uint rands u, v are generated and two statistics are generated: their greatest common divisor (GCD) (w) and the number of steps of Euclid's Method required to find it (k). Two tables of frequencies are thus generated - one for the number of times each value for k in the range 0 to 41 (with counts greater than this range lumped in with the endpoints). The other table is the frequency of occurrence of each GCD with k is be distributed approximately binomially, but this is useless for the purposes of performing a stringent test.  Instead four ``good'' RNGs (gfsr4, mt19937\_1999, rndlxs2, taus2) were used to construct a simulated table of high precision probabilities for k (a process that obviously begs the question as to whether or not THESE generators are ``good'' wrt the test). At any rate, they produce very similar tables and pass the test with each other's tables (and are otherwise very different RNGs).  The table of probabilities for the gcd distribution is generated dynamically per test (it is easy to compute).  Chisq tests on both of these binned distributions yield two p\-values per test, and 100 (default) p\-values of each are accumulated and subjected to final KS tests and displayed in a histogram.
%   
%   \item \textbf{STS Monobit Test. Id(100)} - Very simple. Counts the 1 bits in a long string of random uints. Compares to expected number, generates a p-value directly from erfc().  Very effective at revealing overtly weak generators; Not so good at determining where stronger ones eventually fail.
%   
%   \item \textbf{STS Runs Test. Id(101)} - Counts the total number of 0 runs + total number of 1 runs across a sample of bits.  Note that a 0 run must begin with 10 and end with 01.  Note that a 1 run must begin with 01 and end with a 10. This test, run on a bitstring with cyclic boundary conditions, is absolutely equivalent to just counting the 01 + 10 bit pairs. It is therefore totally redundant with but not as good as the rgb\_bitdist() test for 2-tuples, which looks beyond the means to the moments, testing an entire histogram  of 00, 01, 10, and 11 counts to see if it is binomially distributed with p = 0.25.
%   
%   \item \textbf{STS Serial Test. Id(102)} - Accumulates the frequencies of overlapping n-tuples of bits drawn from a source of random integers.  The expected distribution of n-bit patterns is multinomial with p = $2^{(-n)}$ e.g. the four 2-bit patterns 00 01 10 11 should occur with equal probability. The target distribution is thus a simple chisq with $2^{n} - 1$ degrees of freedom, one lost due to the constraint that: p\_00 + p\_01 + p\_01 + p\_11 = 1 With overlap, though the test statistic is more complex. For example, given a bit string such as 0110100111000110 without overlap, it becomes 01|10|10|01|11|00|01|10 and we count 1 00, 3 01s, 3 10s, and 1 11. WITH overlap we get all of these patterns as well as (with cyclic wrap): 0|11|01|00|11|10|00|11|0 and we count 4 00s, 4 01s, 4 10s, and 3 11s. There is considerable covariance in the bit frequencies and a simple chisq test no longer suffices. The STS test uses target statistics that are valid for overlapping samples but which require multiple orders to generate. It is much easier to write a test that doesn't use overlapping samples and directly checks to ensure that the distribution of bit ntuples is consistent with a multinomial distribution with uniform probability $p = 1/2^n$, e.g. 1/8 for n = 3 bit, 1/16 for n = 4 bit NON-overlapping samples, and the rgb\_bitdist is just such a test. This test doesn't require comparing different orders. An open research question is whether or not test sensitivity significantly depends on managing overlap testing software RNGs where it is presumed that generation is cheap and unlimited. This question pertains to related tests, such as overlapping permutations tests (where non-overlapping permutation tests are isomorphic to non-overlapping frequency tests, fairly obviously). This test does all the possible bitlevel tests from n=1 to n=24 bits (where n=1 is basically sts\_monobit, and n=2 IMO is redundant with sts\_runs).  However, if I understand things correctly it is not possible to fail a 2 bit test and pass a 24 bit test, as if 2 bits are biased so that (say) 00 occurs a bit too often, then 24 bit strings containing 00's MUST be imbalanced as well relative to ones that do not, so we really only need to check n=24 bit results to get all the rest for free, so to speak.
%   
%   \item \textbf{RGB Bit Distribution Test. Id(200)} - Accumulates the frequencies of all n-tuples of bits in a list of random integers and compares the distribution thus generated with the theoretical (binomial) histogram, forming chisq and the associated p-value.  In this test n-tuples are selected without WITHOUT overlap (e.g. 01|10|10|01|11|00|01|10) so the samples are independent.  Every other sample is offset modulus of the sample index and ntuple\_max. This test must be run with -n ntuple for ntuple > 0.  Note that if ntuple > 12, one should probably increase tsamples so that each of the $2^{ntuple}$ bins should end up with an average of around 30 occurrences. Note also that the memory requirements and CPU time requirements will get quite large by e.g. ntuple = 20 - use caution when sampling the distribution of very large ntuples. 
%   
%   \item \textbf{THE GENERALIZED MINIMUM DISTANCE TEST. Id(201)} - This is the generalized minimum distance test, based on the paper of M. Fischler in the doc directory and private communications.  This test utilizes correction terms that are essential in order for the test not to fail for large numbers of trials.  It replaces both diehard\_2dsphere.c and diehard\_3dsphere.c, and generalizes the test itself so that it can be run for any d = 2,3,4,5.  There is no fundamental obstacle to running it for d = 1 or $d\>5$, but one would need to compute the expected overlap integrals (q) for the overlapping d-spheres in the higher dimensions.  Note that in this test there is no real need to stick to the parameters of Marsaglia.  The test by its nature has three controls: n (the number of points used to sample the minimum distance) which determines the granularity of the test - the approximate length scale probed for an excess of density; p, the usual number of trials; and d the dimension.  As Fischler points out, to actually resolve problems with a generator that had areas $20\%$ off the expected density (consistently) in $d = 2, n = 8000$ (Marsaglia's parameters) would require around 2500 trials, where p = 100 (the old test default) would resolve only consistent deviations of around 1.5 times the expected density.  By making both of these user selectable parameters, dieharder should be able to test a generator pretty much as thoroughly as one likes subject to the generous constraints associated with the eventual need for still higher order corrections as n and p are made large enough.
%   
%   \item \textbf{RGB Permutations Test. Id(202)} -  This is a non-overlapping test that simply counts order permutations of random numbers, pulled out n at a time.  There are n! permutations and all are equally likely.  The samples are independent, so one can do a simple chisq test on the count vector with n! - 1 degrees of freedom.  This is a poor-man's version of the overlapping permutations tests, which are much more difficult because of the covariance of the overlapping samples.
%   
%   \item \textbf{RGB Lagged Sums Test. Id(203)} - This package contains many very lovely tests.  Very few of them, however, test for lagged correlations -- the possibility that the random number generator has a bitlevel correlation after some fixed number of intervening bits. The lagged sums test is therefore very simple.   One simply adds up uniform deviates sampled from the rng, skipping lag samples in between each rand used.  The mean of tsamples samples thus summed should be 0,5*tsamples.  The standard deviation should be sqrt(tsamples/12). The experimental values of the sum are thus converted into a p-value (using the erf()) and a ks-test applied to psamples of them.
%   
%   \item \textbf{The Kolmogorov-Smirnov Test Test. Id(204)} - This test generates a vector of tsamples uniform deviates from the selected rng, then applies an Anderson-Darling or Kuiper KS test to it to directly test for uniformity.  The AD version has been symmetrized to correct for weak left bias for small sample sets; Kuiper is already ring-symmetric on the interval.  The AD code corresponds roughly to what is in R (thanks to a correction sent in by David Bauer). As always, the test is run pvalues times and the (same) KS test is then used to generate a final test pvalue, but the real purpose of this test is to test ADKS and KKS, not to test rngs.  This test clearly reveals that kstests run on only 100 test values (tsamples, herein) are only approximately accurate; their pvalues are distinctly high-biased (but less so than Kuiper or KS before the fix).  This bias is hardly visible for less than 1000 trivals (psamples, herein) but will constently cause failure for -t 100, -p 10000 or higher.  For -t 1000, it is much more difficult to detect, and the final kstest is approximately valid for the test in question.
%   
%   \item \textbf{DAB Byte Distribution Test. Id(205)} - Extract n independent bytes from each of k consecutive words. Increment indexed counters in each of n tables.  (Total of 256 $\times$ n counters.) Currently, n=3 and is fixed at compile time. If n>=2, then the lowest and highest bytes will be used, along with n-2 bytes from the middle. If the generator's word size is too small, overlapped bytes will be used. Current, k=3 and is fixed at compile time. Use a basic chisq fitting test (chisq\_pearson) for the p-value. Previous version also used a chisq independence test (chisq2d); it was found to be slightly less sensitive. I envisioned this test as using a small number of samples and large number of separate tests. Experiments so far show that keeping -p 1 and increasing -t performs best.
%   
%   \item \textbf{DCT (Frequency Analysis) Test. Id(206)} - This test performs a Discrete Cosine Transform (DCT) on the output of the RNG. More specifically, it performs tsamples transforms, each over an independent block of ntuple words. If tsamples is large enough, the positions of the maximum (absolute) value in each transform are recorded and subjected to a chisq test for uniformity/independence. [1] (A standard type II DCT is used.)  If tsamples is smaller than or equal to 5 times ntuple then a fallback test will be used, whereby all DCT values are converted to p-values and tested for uniformity via a KS test. This version is significantly less sensitive, and is not recommended. Power: With the right parameters, this test catches more GSL generators than any other; however, that count is biased by each of the randomNNN generators having three copies. Limitations: ntuple is required to be a power of 2, because a radix 2 algorithm is used to calculate the DCT. False positives: targets are (mostly) calculated exactly, however it will still return false positives when ntuple is small and tsamples is very large. For the default ntuple value of 256, I get bad scores with about 100 million or more tsamples (psamples set to 1). [1] The samples are taken as unsigned integers, and the DC coefficient is adjusted to compensate for this.
%   
%   \item \textbf{DAB Fill Tree Test. Id(207)} - This test fills small binary trees of fixed depth with words from the the RNG.  When a word cannot be inserted into the tree, the current count of words in the tree is recorded, along with the position at which the word would have been inserted. The words from the RNG are rotated (in long cycles) to better detect RNGs that may bias only the high, middle, or low bytes. The test returns two p-values.  The first is a Pearson chi-sq test against the expected values (which were estimated empirically).  The second is a Pearson chi-sq test for a uniform distribution of the positions at which the insert failed. Because of the target data for the first p-value, ntuple must be kept at the default (32).
%   
%   \item \textbf{DAB Fill Tree 2 Test. Id(208)} - Bit version of Fill Tree test. This test fills small binary trees of fixed depth with `visited´ markers.  When a marker cannot be placed, the current count of markers in the tree and the position that the marker would have been inserted, if it hadn't already been marked. For each bit in the RNG input, the test takes a step right (for a zero) or left (for a one) in the tree. If the node hasn't been marked, it is marked, and the path restarts.  Otherwise, the test continues with the next bit. The test returns two p-values.  The first is a Pearson chi-sq test against the expected values (which were estimated empirically.  The second is a Pearson chi-sq test for a uniform distribution of the positions at which the insert failed. Because of the target data for the first p-value, ntuple must be kept at the default (128).
%   
%   \item \textbf{DAB Monobit 2 Test. Id(209)} - Block-monobit test. Since we don't know what block size to use, try multiple block sizes. In particular, try all block sizes of $2^k$ words, where k={0 \dots n}.  The value of n is calculated from the word size of the generator and the sample size used, and is shown as ntuple.
% \end{itemize} 

  \subsection{ENT}
  
  \subsection{TestU01}

\section{Delimitação do problema} %Delimitação do problema  


\begin{center}
	\fbox{
	\colorbox[RGB]{227, 227, 227}{
	\parbox[t]{.8\linewidth}
		{Neste capítulo tratamos da Revisão Bibliográfica realizada para o desenvolvimento do trabalho, no capítulo seguinte tratamos da metodologia utilizada do desenvolvimento do mesmo.}} }
\end{center}

